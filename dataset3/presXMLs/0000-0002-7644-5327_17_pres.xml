<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /mnt/sda1/Dissertation/grobid/grobid-0.5.6/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Multi-agent reinforcement learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2019-12-22">December 22, 2019</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Schnebli</forename><surname>Zoltan</surname></persName>
						</author>
						<title level="a" type="main">Multi-agent reinforcement learning</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2019-12-22">December 22, 2019</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.5.6" ident="GROBID" when="2019-12-24T15:31+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Bidding Agents for 
Online Auctions with 
.=</p>
<p>Hidden Bids
.=</p>
<p>Kevin Leyton-Brown
Department of Computer Science
.=</p>
<p>University of British Columbia
.=</p>
<p>joint work with
.=</p>
<p>Albert Xin Jiang.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Bidding Agents
• Given a bidding history, but no explicit valuation distribution, compute a 
.=</p>
<p>bidding strategy that maximizes EU
– Motivating example: how should agents behave in a sequence of eBay auctions?
.=</p>
<p>• Game Theoretic Approach [Athey&Haile, 2000], [Haile&Tamer, 2003], [Rogers et al., 2005]
– model the situation as a Bayesian game
– estimate other bidders’ valuations from the history
– compute and then play a Bayes-Nash equilibrium of the game
.=</p>
<p>• Decision Theoretic Approach [Boutilier et al., 1999], [Byde, 2002], [Stone et al., 2003], 
[Greenwald & Boyan, 2004], [MacKie-Mason et al., 2004], [Osepayshvili et al., 2005]
.=</p>
<p>– learn the behavior of other bidders from historical data
• treat other bidders as part of the environment
.=</p>
<p>– play an optimal strategy in the resulting single-agent decision problem
.=</p>
<p>• Fundamental subproblem: using historical data to estimate distribution of 
bidders’ bid amounts or valuations
.=</p>
<p>– …why is there still any work to be done?.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Talk Outline
.=</p>
<p>1. Background
.=</p>
<p>2. Online Auction Model and Learning Problem
.=</p>
<p>3. Bidding in Sequential Auctions
.=</p>
<p>4. Experimental Evaluation
.=</p>
<p>5. Conclusions.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Online Auction Model
• A (possibly repeated) online English auction such as eBay
.=</p>
<p>– m potential bidders, with m drawn from a distribution g(m)
• let n denote the number of bidders who place (accepted) bids in the auction
.=</p>
<p>– each bidder i has an independent private valuation drawn from distribution f(v)
.=</p>
<p>• Bidding dynamics
– start with reserve price of zero
– bidders sequentially place proxy bids  (each bidder gets only one bid)
– auctioneer maintains current price: second-highest proxy amount declared so far
– if a new bid is less than the current price, it is dropped
.=</p>
<p>• Bidding history
– some bidders’ proxy bid amounts will be perfectly observed (denote this set of bids xo)
.=</p>
<p>• any bidder who placed a proxy bid and was outbid  (n-1 such bidders)
– however, some bids will be hidden (denote this set xh)
.=</p>
<p>• highest bid (one bidder)
– revealed only up to the second-highest bidder’s proxy amount
.=</p>
<p>• any bid which was lower than the current price when it was placed (m – n bidders)
– either the bidder leaves or the bid is rejected .=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Bidding Example
.=</p>
<p>8
.=</p>
<p>7
.=</p>
<p>6
.=</p>
<p>5
.=</p>
<p>4
.=</p>
<p>3
.=</p>
<p>2
.=</p>
<p>1
.=</p>
<p>0
1 2 3 4 5 6 7
.=</p>
<p>chuigrhreenstt
price.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Learning the Distributions f(v) and g(m)
.=</p>
<p>• Data: a set of auction histories
– number of bidders and bids distributed identically in each auction
.=</p>
<p>• Simple technique for estimating f(v) and g(m): 
– ignore hidden bids, considering only xo and n from each auction
– use any standard density estimation technique to learn the distributions
– essentially this is the straightforward price estimation technique described earlier
.=</p>
<p>• Problem: 
– the simple technique ignores the hidden bids and so introduces bias
– g(m) will be skewed towards small values because n ≤ m
– f(v) may be
.=</p>
<p>• skewed towards small values because it ignores the winning bid
• skewed towards large values because ignores dropped, losing bids.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>EM Algorithm
.=</p>
<p>• Solution: use EM to account for hidden bids
– similar in spirit to an approach by Boutilier et al. [1999]
– I’ll discuss related work at the end; short answer: our setting is different
.=</p>
<p>• E step:  generate the missing data given estimates of f', g' and bidding model
– for each observation xo, repeat until N samples of xh have been generated:
.=</p>
<p>• sample m from g'(m | m ≥ n)
• draw m – n + 1 samples from f'(v) to represent a hidden bids
• if xh does not contain exactly one bid that exceeds the highest bid in xo, reject sample.
.=</p>
<p>• M step:  
– update f '(v) and g'(m) to maximize the likelihood of the bids xo ∪ xh
.=</p>
<p>• depends on functional form of f', g'; either analytic or using e.g. simulated annealing.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Learning f(v) and g(m) in a Game Theoretic Setting
.=</p>
<p>• The approach described above is decision-theoretic
• What if we want to take a game-theoretic approach?
.=</p>
<p>– Athey & Haile [2000] discuss estimation in the game theoretic setting
• however, they generally assume that number of bidders is known
.=</p>
<p>– let f(v) be the distribution of bidder’s valuations (instead of bid amounts)
• g(m) remains the distribution of number of bidders, as before
.=</p>
<p>– given a bidder’s valuation v, what is his bid amount?
• solve for Bayes-Nash equilibrium of the auction game: bid function b(v |f, g)
.=</p>
<p>• EM algorithm to estimate f and g in a GT setting:
– E step:  for each sample given observation xo:
.=</p>
<p>• sample m from g'(m | m ≥ n)
• compute observed bidders’ valuations vo from xo by inverting the bid function
• generate new bidders with valuations vh who place hidden bids xh = b(vh|f', g')
.=</p>
<p>– generate m – n + 1 bids, keeping samples when exactly one hidden bid is higher than the 
highest observed bid
.=</p>
<p>– M step:  update f' and g' to maximize likelihood of the valuations vo ∪ vh.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Talk Outline
.=</p>
<p>1. Background
.=</p>
<p>2. Online Auction Model and Learning Problem
.=</p>
<p>3. Building an Agent
.=</p>
<p>4. Experimental Evaluation
.=</p>
<p>5. Conclusions.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Building an Agent
.=</p>
<p>• Auction environment
– k sequential, single-good online auctions for possibly non-identical goods
– we want only one item
.=</p>
<p>• e.g. buying a Playstation 2 from eBay, where such auctions are held regularly
– denote our valuation for the item in auction j as vj and our bid as bj
– let Uj denote expected payoff at time j, conditional on not having won already
.=</p>
<p>• a function of our valuations for the goods in the auctions j, …, k
.=</p>
<p>• Consider the construction of a decision-theoretic agent to participate in a 
finite sequence of auctions (under our online auction model)
.=</p>
<p>– given estimates f'(v) and g'(m), what are the optimal bidding strategies?
.=</p>
<p>• Greenwald & Boyan [2004] and Arora et al. [2003] analyzed similar domains
– using similar reasoning, we derive the optimal bidding strategy for our model.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Computing the Optimal Strategy
.=</p>
<p>• Optimal bidding: 
– is the EU of the bidding strategy that maximizes Uj+1 (derived in the paper)
.=</p>
<p>• first term: payoff from current auction; second term: payoff from future auctions
• note that Uj+1 depends on the distribution of the highest bid:
.=</p>
<p>• …and that F 1j depends in turn on f(x), g(m)
• thus we must estimate f(x), g(m) to build a decision theoretic agent in this setting
.=</p>
<p>• Our agent computes U*j+1 by approximating an integral using Monte Carlo 
sampling, again relying on our model of the auction.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Game Theoretic Approach
.=</p>
<p>• If each bidder (other than our agent) only participates in one auction:
– dominant strategy is to bid truthfully: b(v) = v
– we can use the decision-theoretic approach
.=</p>
<p>• If other bidders participate in more than one auction [Milgrom & Weber, 1982]
– equilibrium strategy gets more complex (both strategically and computationally)
– success in this domain is much harder to benchmark experimentally
.=</p>
<p>• do we believe that all agents will follow an equilibrium strategy on eBay?
.=</p>
<p>• We analyzed game theoretic bidding in online auctions without proxies
– we derived Bayes-Nash equilibrium for this game
– used EM to learn distributions f(v) and g(m).=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Talk Outline
.=</p>
<p>1. Background
.=</p>
<p>2. Online Auction Model and Learning Problem
.=</p>
<p>3. Building an Agent
.=</p>
<p>4. Experimental Evaluation
.=</p>
<p>5. Conclusions.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Experiments
.=</p>
<p>• We compared our EM approach to the simple approach
I. Synthetic data: sequence of auctions for identical items 
.=</p>
<p>(decision theoretic), known distribution families
II. Synthetic data: sequence of auctions for non-identical items
.=</p>
<p>(decision theoretic), known distribution families
III. Synthetic data: sequence of auctions for identical items 
.=</p>
<p>(decision theoretic), unknown distribution families
IV. eBay data: auctions for Playstation 2, March 2005 (decision theoretic),
V. Synthetic data: online auction without proxies (game theoretic),
.=</p>
<p>known distribution families
.=</p>
<p>• For each dataset, we ask two of the following three questions:
1. Which approach gives better estimates of the distributions 
.=</p>
<p>f(v), g(m), f1(v)? 
2. Decision theoretic: which approach gives better expected payoffs?
3. Game theoretic: which approach finds ε-equilibria for smaller ε?.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Data Set I: Identical Items
• Synthetic Data: f(v) is a normal distribution; g(m) is a Poisson distribution
• Bidding history of 40 auctions is generated for each instance.
• Both learning approaches use the correct (normal & Poisson) families of distributions to 
.=</p>
<p>estimate f(v) and g(m)
• Question 1: which approach made a better estimate of f(v), g(m), f1(v)?
.=</p>
<p>Distribution of Bids
0.14
.=</p>
<p>true
simple
.=</p>
<p>0.12 EM
.=</p>
<p>0.1
.=</p>
<p>0.08
.=</p>
<p>0.06
.=</p>
<p>0.04
.=</p>
<p>0.02
.=</p>
<p>0
−6 −4 −2 0 2 4 6 8 10 12 14
.=</p>
<p>Bid Amount
.=</p>
<p>– EM approach consistently has lower KL divergence than the simple approach
– statistically significant difference: Wilcoxon sign-rank test (non-parametric).=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Data Set I: Comparing Expected Payoffs
• Sequence of eight new auctions, after learning from the 40-auction history
.=</p>
<p>– in the new auctions, we still use the true g(m) and f(v)
.=</p>
<p>• Question 2: following the optimal strategy with the EM estimates gives higher 
expected payoffs than following this strategy with the simple approach’s estimates
.=</p>
<p>Payoff Regrets
.=</p>
<p>0.3
.=</p>
<p>0.25
.=</p>
<p>0.2
.=</p>
<p>0.15
.=</p>
<p>0.1
.=</p>
<p>0.05
.=</p>
<p>0
.=</p>
<p>simple EM
.=</p>
<p>Regret.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Data Set II: Non-identical Items
.=</p>
<p>• The mean of f(v) depends linearly on some unknown parameter a
• Both approaches use linear regression to estimate the linear coefficients
• Question 1: EM approach gives (stat. significantly) better estimates
.=</p>
<p>The mean of f(x|a) versus a
13
.=</p>
<p>true
simple
.=</p>
<p>12 EM
.=</p>
<p>11
.=</p>
<p>10
.=</p>
<p>9
.=</p>
<p>8
.=</p>
<p>7
.=</p>
<p>6
.=</p>
<p>5
.=</p>
<p>4
3 4 5 6 7 8 9
.=</p>
<p>a
.=</p>
<p>• Question 2: EM approach achieves significantly better expected payoffs 
.=</p>
<p>mean of f(x|a).=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Data Set III: Unknown distributions
• Identical items.  Distribution families for f(v) and g(m) are unknown
.=</p>
<p>– ground truth: f(v) is Gamma distributed; g(m) is a mixture of two Poissons
• Use kernel density estimation to estimate f(v) and g(m)
• Result: the EM approach gives better estimates (significantly lower KL divergence); 
.=</p>
<p>both approaches achieved similar payoffs (difference not significant).=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Data Set IV: eBay Data
• 60 Sony Playstation-2 auctions from eBay, March 2005
.=</p>
<p>– considered only one-day auctions with at least 3 bidders
.=</p>
<p>• Problem: highest bids not available
• Workaround: “pretend” second-highest bid is the highest bid 
.=</p>
<p>– justification: this “shifted” data set should have similar characteristics to the actual 
bidding history
.=</p>
<p>• Compared four approaches:
– EM, simple approaches estimating normal and Poisson distributions
– EM, simple approaches using kernel density estimation
.=</p>
<p>• Question 1: no ground truth for this data set—dropped bids are really dropped, etc. 
• Question 2: the EM approaches achieve significantly higher expected payoffs than the 
.=</p>
<p>simple approaches.
Payoff Regrets
.=</p>
<p>5
.=</p>
<p>4
.=</p>
<p>3
.=</p>
<p>2
.=</p>
<p>1
.=</p>
<p>0
.=</p>
<p>simple simple kernel EM EM kernel
.=</p>
<p>Regret.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Data Set V: Online Auctions without Proxies
.=</p>
<p>• Synthetic Data: f(v) is a normal distribution; g(m) is a Poisson distribution
• Bidding history of 30 auctions is generated for each instance.
• Both learning approaches use the correct (normal & Poisson) families of 
.=</p>
<p>distributions to estimate f(v) and g(m)
• Question 1: EM approach gives (stat. significantly) better estimates
• Question 3: EM approach computes ε-equilibria with significantly smaller ε..=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Talk Outline
.=</p>
<p>1. Background
.=</p>
<p>2. Online Auction Model and Learning Problem
.=</p>
<p>3. Building an Agent
.=</p>
<p>4. Experimental Evaluation
.=</p>
<p>5. Conclusions.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Conclusions: Related Work on the Hidden Bid Problem
.=</p>
<p>• [Boutilier et al. 1999]: 
– a decision-theoretic MDP approach to bidding in sequential first-price auctions for 
.=</p>
<p>complementary goods
– for the case where these sequential auctions are repeated, discusses learning a distribution 
.=</p>
<p>of other agents’ highest bid for each good, based on winning bids
• uses EM: the agent’s own bid wins, hiding the highest bid by other agents
.=</p>
<p>• [Rogers et al., 2005]:
– English auctions with discrete bid levels, unknown # bidders; want to find optimal design
– look at the final prices to compute posterior distributions (Bayesian inference)
– ignores all the earlier bids (thus higher variance); 
– works only for parametric distributions, and is exponential in the number of parameters
.=</p>
<p>• [Song, 2004]:
– English auctions in eBay-like environments
– use second- and third-highest bids to estimate the value distribution
– problem: third-highest bids sometimes hidden; using the observed bids introduces bias
.=</p>
<p>• [Haile & Tamer, 2003]
– study a different problem: bidders’ final observed bids may be below their valuations
– solve the problem by computing bounds on the value distributions
– intended for physical auctions with known numbers of bidders; introduces bias when 
.=</p>
<p>applied to online auctions with unknown numbers of bidders
– interesting open question: combining with our methods for unknown number of bidders.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Conclusion & Future Work
.=</p>
<p>• Bidding agents in online auction settings face the problem of estimating
– distribution of bid amounts;
– distribution of number of bidders 
.=</p>
<p>from incomplete auction data
.=</p>
<p>• We proposed a learning approach based on EM
.=</p>
<p>• We considered the application of building a decision theoretic agent
for sequences of online auctions
– Also a game theoretic agent for online auctions without proxies
.=</p>
<p>• We showed in experiments that our EM approach never did worse and 
usually did better than the straightforward approach, on both synthetic and 
real-world data
.=</p>
<p>• Recently published in MLJ; available at http://cs.ubc.ca/~kevinlb.=</p>
</div>
</body>
		<back>
			<div type="references">

				<listBibl>


				</listBibl>
			</div>
		</back>
	</text>
</TEI>
