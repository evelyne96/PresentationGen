<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /mnt/sda1/Dissertation/grobid/grobid-0.5.6/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Multi-agent reinforcement learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2019-12-22">December 22, 2019</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Schnebli</forename><surname>Zoltan</surname></persName>
						</author>
						<title level="a" type="main">Multi-agent reinforcement learning</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2019-12-22">December 22, 2019</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.5.6" ident="GROBID" when="2019-12-24T15:31+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Beyond Equilibrium: Predicting Human Behavior
in Normal-Form Games
.=</p>
<p>James Wright & Kevin Leyton-Brown
University of British Columbia
.=</p>
<p>July 15, 2010
.=</p>
<p>Introduction Framework Experimental setup Results Conclusions 1.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Context
.=</p>
<p>‚Ä¢ Game theory: Mathematical study of behavior in idealized
strategic multiagent settings.
.=</p>
<p>‚Ä¢ Idealized agents, not human agents.
‚Ä¢ Behavioral game theory: Aims to extend game theory to
.=</p>
<p>modelling human agents.
‚Ä¢ There are a wide range of BGT models in the literature.
‚Ä¢ BGT focuses on explaining behavior rather than predicting it.
‚Ä¢ Not much work compares different models‚Äô predictive power.
.=</p>
<p>Introduction Framework Experimental setup Results Conclusions 2.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Game theory: Normal form game
.=</p>
<p>In a normal form game:
.=</p>
<p>‚Ä¢ Each agent simultaneously chooses an action from a finite
action set.
.=</p>
<p>‚Ä¢ Each combination of actions yields a known utility to each
agent.
.=</p>
<p>‚Ä¢ The agents may choose actions either deterministically or
stochastically.
.=</p>
<p>Introduction Framework Experimental setup Results Conclusions 3.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Nash equilibrium
.=</p>
<p>‚Ä¢ In a Nash equilibrium, each agent best responds to the others.
‚Ä¢ An agent best responds to other agents‚Äô actions by choosing a
.=</p>
<p>strategy that maximizes utility, conditional on the other
agents‚Äô strategies.
.=</p>
<p>BRi (s‚àíi ) = arg max ui (si , s‚àíi )
si
.=</p>
<p>Introduction Framework Experimental setup Results Conclusions 4.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>2 96‚àí 298=+942 = 10099‚àí1200= 97
.=</p>
<p>2 96 + 2 = 98 9998+‚àí22= 19016100
.=</p>
<p>‚Ä¢ If they pick the same number, that is their payoff.
‚Ä¢ If the pick different numbers:
.=</p>
<p>‚Ä¢ Lower player gets lower number, plus bonus of 2.
‚Ä¢ Higher player gets lower number, minus penalty of 2.
.=</p>
<p>‚Ä¢ Traveler‚Äôs Dilemma has a unique Nash equilibrium.
.=</p>
<p>Example: Traveler‚Äôs Dilemma
.=</p>
<p>. . .
2 3 4 96 97 98 99 100
.=</p>
<p>‚Ä¢ Two players pick a number (2-100) simultaneously.
.=</p>
<p>Introduction Framework Experimental setup Results Conclusions 5.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>2 96‚àí 298=+942 = 10099‚àí1200= 97
.=</p>
<p>2 96 + 2 = 98 9998+‚àí22= 19016100
.=</p>
<p>‚Ä¢ If the pick different numbers:
‚Ä¢ Lower player gets lower number, plus bonus of 2.
‚Ä¢ Higher player gets lower number, minus penalty of 2.
.=</p>
<p>‚Ä¢ Traveler‚Äôs Dilemma has a unique Nash equilibrium.
.=</p>
<p>Example: Traveler‚Äôs Dilemma
.=</p>
<p>100
.=</p>
<p>. . .
2 3 4 96 97 98 99 100
.=</p>
<p>100
.=</p>
<p>‚Ä¢ Two players pick a number (2-100) simultaneously.
‚Ä¢ If they pick the same number, that is their payoff.
.=</p>
<p>Introduction Framework Experimental setup Results Conclusions 5.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>2 98 + 2 = 10099‚àí1200= 97
.=</p>
<p>2 9998+‚àí22= 19016100
.=</p>
<p>‚Ä¢ Traveler‚Äôs Dilemma has a unique Nash equilibrium.
.=</p>
<p>Example: Traveler‚Äôs Dilemma
.=</p>
<p>96‚àí 2 = 94
.=</p>
<p>. . .
2 3 4 96 97 98 99 100
.=</p>
<p>96 + 2 = 98
.=</p>
<p>‚Ä¢ Two players pick a number (2-100) simultaneously.
‚Ä¢ If they pick the same number, that is their payoff.
‚Ä¢ If the pick different numbers:
.=</p>
<p>‚Ä¢ Lower player gets lower number, plus bonus of 2.
‚Ä¢ Higher player gets lower number, minus penalty of 2.
.=</p>
<p>Introduction Framework Experimental setup Results Conclusions 5.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>2 96‚àí 298=+942 = 10099‚àí1200= 97
.=</p>
<p>2 96 + 2 = 98 9998+‚àí22= 19016100
.=</p>
<p>Example: Traveler‚Äôs Dilemma
.=</p>
<p>100
.=</p>
<p>. . .
2 3 4 96 97 98 99 100
.=</p>
<p>100
.=</p>
<p>‚Ä¢ Two players pick a number (2-100) simultaneously.
‚Ä¢ If they pick the same number, that is their payoff.
‚Ä¢ If the pick different numbers:
.=</p>
<p>‚Ä¢ Lower player gets lower number, plus bonus of 2.
‚Ä¢ Higher player gets lower number, minus penalty of 2.
.=</p>
<p>‚Ä¢ Traveler‚Äôs Dilemma has a unique Nash equilibrium.
.=</p>
<p>Introduction Framework Experimental setup Results Conclusions 5.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>2 96‚àí 298=+942 = 100 100
.=</p>
<p>2 96 + 2 = 98 98‚àí 2 = 91600
.=</p>
<p>Example: Traveler‚Äôs Dilemma
.=</p>
<p>99‚àí 2 = 97
.=</p>
<p>. . .
2 3 4 96 97 98 99 100
.=</p>
<p>99 + 2 = 101
.=</p>
<p>‚Ä¢ Two players pick a number (2-100) simultaneously.
‚Ä¢ If they pick the same number, that is their payoff.
‚Ä¢ If the pick different numbers:
.=</p>
<p>‚Ä¢ Lower player gets lower number, plus bonus of 2.
‚Ä¢ Higher player gets lower number, minus penalty of 2.
.=</p>
<p>‚Ä¢ Traveler‚Äôs Dilemma has a unique Nash equilibrium.
.=</p>
<p>Introduction Framework Experimental setup Results Conclusions 5.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>2 96‚àí 2 = 94 99‚àí1200= 97
.=</p>
<p>2 96 + 2 = 98 99 + 2 = 101100
.=</p>
<p>Example: Traveler‚Äôs Dilemma
.=</p>
<p>98 + 2 = 100
.=</p>
<p>. . .
2 3 4 96 97 98 99 100
.=</p>
<p>98‚àí 2 = 96
.=</p>
<p>‚Ä¢ Two players pick a number (2-100) simultaneously.
‚Ä¢ If they pick the same number, that is their payoff.
‚Ä¢ If the pick different numbers:
.=</p>
<p>‚Ä¢ Lower player gets lower number, plus bonus of 2.
‚Ä¢ Higher player gets lower number, minus penalty of 2.
.=</p>
<p>‚Ä¢ Traveler‚Äôs Dilemma has a unique Nash equilibrium.
.=</p>
<p>Introduction Framework Experimental setup Results Conclusions 5.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>96‚àí 298=+942 = 10099‚àí1200= 97
.=</p>
<p>96 + 2 = 98 9998+‚àí22= 19016100
.=</p>
<p>Example: Traveler‚Äôs Dilemma
.=</p>
<p>2
.=</p>
<p>. . .
2 3 4 96 97 98 99 100
.=</p>
<p>2
.=</p>
<p>‚Ä¢ Two players pick a number (2-100) simultaneously.
‚Ä¢ If they pick the same number, that is their payoff.
‚Ä¢ If the pick different numbers:
.=</p>
<p>‚Ä¢ Lower player gets lower number, plus bonus of 2.
‚Ä¢ Higher player gets lower number, minus penalty of 2.
.=</p>
<p>‚Ä¢ Traveler‚Äôs Dilemma has a unique Nash equilibrium.
.=</p>
<p>Introduction Framework Experimental setup Results Conclusions 5.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>‚Ä¢ Clearly Nash equilibrium is not the whole story.
‚Ä¢ Behavioral game theory proposes a number of models to
.=</p>
<p>better explain human behavior.
.=</p>
<p>Nash equilibrium and human subjects
.=</p>
<p>‚Ä¢ Nash equilibrium often makes counterintuitive predictions.
‚Ä¢ In Traveler‚Äôs Dilemma: The vast majority of human players
.=</p>
<p>choose 97‚Äì100.
.=</p>
<p>‚Ä¢ Modifications to a game that don‚Äôt change Nash equilibrium
predictions at all can cause large changes in how human
subjects play the game [Goeree & Holt 2001].
.=</p>
<p>‚Ä¢ In Traveler‚Äôs Dilemma: When the penalty is large, people play
much closer to Nash equilibrium.
.=</p>
<p>‚Ä¢ But the size of the penalty does not effect equilibrium.
.=</p>
<p>Introduction Framework Experimental setup Results Conclusions 6.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Nash equilibrium and human subjects
.=</p>
<p>‚Ä¢ Nash equilibrium often makes counterintuitive predictions.
‚Ä¢ In Traveler‚Äôs Dilemma: The vast majority of human players
.=</p>
<p>choose 97‚Äì100.
.=</p>
<p>‚Ä¢ Modifications to a game that don‚Äôt change Nash equilibrium
predictions at all can cause large changes in how human
subjects play the game [Goeree & Holt 2001].
.=</p>
<p>‚Ä¢ In Traveler‚Äôs Dilemma: When the penalty is large, people play
much closer to Nash equilibrium.
.=</p>
<p>‚Ä¢ But the size of the penalty does not effect equilibrium.
.=</p>
<p>‚Ä¢ Clearly Nash equilibrium is not the whole story.
‚Ä¢ Behavioral game theory proposes a number of models to
.=</p>
<p>better explain human behavior.
.=</p>
<p>Introduction Framework Experimental setup Results Conclusions 6.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Behavioral game theory models
.=</p>
<p>Themes:
.=</p>
<p>1 Quantal response: Agents best-respond with high probability
rather than deterministically best responding.
.=</p>
<p>2 Iterative strategic reasoning: Agents can only perform limited
steps of strategic ‚Äúlook-ahead‚Äù.
.=</p>
<p>One model is based on quantal response, two models are based on
iterative strategic reasoning, and one model incorporates both.
.=</p>
<p>Introduction Framework Experimental setup Results Conclusions 7.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>BGT model: Quantal response equilibrium (QRE)
.=</p>
<p>QRE model [McKelvey & Palfrey 1995]
.=</p>
<p>‚Ä¢ Agents quantally best respond to each other.
.=</p>
<p>eŒªui (ai ,s‚àíi )
QBRi (s‚àíi )(ai ) = ‚àë Œªui (a‚Ä≤,s )
.=</p>
<p>a‚Ä≤
‚àíi
.=</p>
<p>i‚àà
i
.=</p>
<p>A ei
.=</p>
<p>‚Ä¢ Precision parameter Œª ‚àà [0,‚àû) indicates how sensitive agents
are to utility differences.
.=</p>
<p>‚Ä¢ Œª = 0 means agents choose actions uniformly at random.
‚Ä¢ As Œª‚Üí‚àû, QRE approaches Nash equilibrium.
.=</p>
<p>Introduction Framework Experimental setup Results Conclusions 8.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>BGT models: Level-k models
.=</p>
<p>‚Ä¢ Each agent has one of 3 levels: Level-0, level-1, or level-2.
‚Ä¢ Level-0 agents choose uniformly at random.
‚Ä¢ Level-1 agents believe that all opponents are level-0.
‚Ä¢ Level-2 agents believe that all opponents are level-1.
‚Ä¢ Two variants considered:
.=</p>
<p>‚Ä¢ Lk
‚Ä¢ Quantal level-k (QLk)
.=</p>
<p>. . .
2 3 4 96 97 98 99 100
.=</p>
<p>Introduction Framework Experimental setup Results Conclusions 9.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>BGT model: Lk
.=</p>
<p>Lk model [Costa-Gomes et al. 2001]
.=</p>
<p>‚Ä¢ Each level-k agent makes a ‚Äúmistake‚Äù with probability k , or
best responds to level-(k ‚àí 1) opponent with probability
1‚àí k .
.=</p>
<p>‚Ä¢ Level-k agents aren‚Äôt aware that level-(k ‚àí 1) agents will
make ‚Äúmistakes‚Äù.
.=</p>
<p>IBRi ,0 = Ai ,
.=</p>
<p>IBRi ,k = BRi (IBR‚àíi ,k‚àí1),
.=</p>
<p>œÄLk(a ) = {|A |‚àí1i ,0 i i ,
Lk (1‚àí k)/|IBRi ,k | if ai ‚àà IBRi ,k ,œÄi ,k(ai ) =
.=</p>
<p>k/(|Ai | ‚àí |IBRi ,k |) otherwise.
.=</p>
<p>Introduction Framework Experimental setup Results Conclusions 10.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>BGT model: QLk
.=</p>
<p>QLk model [Stahl & Wilson 1994]
.=</p>
<p>‚Ä¢ Each agent quantally responds to next-lower level.
‚Ä¢ Each QLk agent level has its own precision (Œªk), and its own
.=</p>
<p>beliefs about lower-level agents‚Äô precisions (¬µk,`).
.=</p>
<p>œÄQLk ‚àí1i ,0 (ai ) = |Ai | ,
.=</p>
<p>œÄQLki ,1 = QBR (œÄ
QLk
.=</p>
<p>i ‚àíi ,0 | Œª1),
.=</p>
<p>œÄQLki ,2 = QBRi (Œ≥ | Œª2).
.=</p>
<p>Introduction Framework Experimental setup Results Conclusions 11.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>BGT model: Cognitive hierarchy
.=</p>
<p>‚Ä¢ Each agent has a non-negative level.
‚Ä¢ An agent of level m best responds to the truncated, true
.=</p>
<p>distribution of levels from 0 to m ‚àí 1.
‚Ä¢ Poisson-CH [Camerer et al. 2004]: Levels are assumed to have a
.=</p>
<p>Poisson distribution.
.=</p>
<p>œÄPCHi ,0 (ai ) = {|A |‚àí1i ,
|TBR ‚àí1i ,m| if ai ‚àà TBRi ,m,
.=</p>
<p>œÄPCHi ,m (ai ) =
0 (‚àë othe)rwise.m‚àí1
.=</p>
<p>TBR = BR F (`)œÄPCHi ,m i ‚àíi ,`
`=0
.=</p>
<p>Introduction Framework Experimental setup Results Conclusions 12.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>‚Ä¢ We constructed two different Nash-based models to deal with
multiple equilibria:
.=</p>
<p>‚Ä¢ UNEE: Take the average of all Nash equilibria.
‚Ä¢ NNEE: Predict using the post-hoc ‚Äúbest‚Äù Nash equilibrium.
.=</p>
<p>‚Ä¢ Both models avoid probability 0 predictions via a tunable error
probability.
.=</p>
<p>Prediction using Nash equilibrium
.=</p>
<p>‚Ä¢ We would like to compare BGT models‚Äô prediction
performance to Nash equilibrium.
.=</p>
<p>‚Ä¢ Unmodified Nash equilibrium is not suitable for predictions:
1 Games often have multiple Nash equilibria.
2 A Nash equilibrium will often assign probability 0 to some
.=</p>
<p>actions.
.=</p>
<p>Introduction Framework Experimental setup Results Conclusions 13.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Prediction using Nash equilibrium
.=</p>
<p>‚Ä¢ We would like to compare BGT models‚Äô prediction
performance to Nash equilibrium.
.=</p>
<p>‚Ä¢ Unmodified Nash equilibrium is not suitable for predictions:
1 Games often have multiple Nash equilibria.
2 A Nash equilibrium will often assign probability 0 to some
.=</p>
<p>actions.
.=</p>
<p>‚Ä¢ We constructed two different Nash-based models to deal with
multiple equilibria:
.=</p>
<p>‚Ä¢ UNEE: Take the average of all Nash equilibria.
‚Ä¢ NNEE: Predict using the post-hoc ‚Äúbest‚Äù Nash equilibrium.
.=</p>
<p>‚Ä¢ Both models avoid probability 0 predictions via a tunable error
probability.
.=</p>
<p>Introduction Framework Experimental setup Results Conclusions 13.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>1 Evaluation criteria
‚Ä¢ Metric to measure performance
‚Ä¢ Statistical test to evaluate significance
.=</p>
<p>2 Experimental data
‚Ä¢ Training data to fit model parameters
‚Ä¢ Test data to evaluate models on
.=</p>
<p>Experimental setup: Overview
.=</p>
<p>What do we need to compare predictive models?
.=</p>
<p>Introduction Framework Experimental setup Results Conclusions 14.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>2 Experimental data
‚Ä¢ Training data to fit model parameters
‚Ä¢ Test data to evaluate models on
.=</p>
<p>Experimental setup: Overview
.=</p>
<p>What do we need to compare predictive models?
.=</p>
<p>1 Evaluation criteria
‚Ä¢ Metric to measure performance
‚Ä¢ Statistical test to evaluate significance
.=</p>
<p>Introduction Framework Experimental setup Results Conclusions 14.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Experimental setup: Overview
.=</p>
<p>What do we need to compare predictive models?
.=</p>
<p>1 Evaluation criteria
‚Ä¢ Metric to measure performance
‚Ä¢ Statistical test to evaluate significance
.=</p>
<p>2 Experimental data
‚Ä¢ Training data to fit model parameters
‚Ä¢ Test data to evaluate models on
.=</p>
<p>Introduction Framework Experimental setup Results Conclusions 14.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>‚Ä¢ The parameters are chosen to maximize the likelihood of the
training data:
.=</p>
<p>#¬ª‚àó D | M #¬ªŒ∏ = arg maxP( train , Œ∏ ).
#¬ª
Œ∏
.=</p>
<p>1. Evaluation criteria: Metric
.=</p>
<p>‚Ä¢ We score the performance of a model by the likelihood of the
test data:
.=</p>
<p>P(D #¬ª‚àótest | M, Œ∏ ).
.=</p>
<p>Introduction Framework Experimental setup Results Conclusions 15.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>1. Evaluation criteria: Metric
.=</p>
<p>‚Ä¢ We score the performance of a model by the likelihood of the
test data:
.=</p>
<p>#¬ª
.=</p>
<p>P(Dtest | M, Œ∏ ‚àó).
.=</p>
<p>‚Ä¢ The parameters are chosen to maximize the likelihood of the
training data:
.=</p>
<p>#¬ª‚àó D | M #¬ªŒ∏ = arg maxP( train , Œ∏ ).
#¬ª
Œ∏
.=</p>
<p>Introduction Framework Experimental setup Results Conclusions 15.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>‚Ä¢ Problem: Results may depend upon the particular partition
into folds.
.=</p>
<p>‚Ä¢ We average over multiple cross-validation runs.
‚Ä¢ We can then compute 95% confidence interval by assuming a
t-distribution of these averages [Witten & Frank 2000].
.=</p>
<p>1. Evaluation criteria: Statistical test
.=</p>
<p>‚Ä¢ For lower-variance estimate of performance, we use 10-fold
cross-validation.
.=</p>
<p>Introduction Framework Experimental setup Results Conclusions 16.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>‚Ä¢ We average over multiple cross-validation runs.
‚Ä¢ We can then compute 95% confidence interval by assuming a
t-distribution of these averages [Witten & Frank 2000].
.=</p>
<p>1. Evaluation criteria: Statistical test
.=</p>
<p>‚Ä¢ For lower-variance estimate of performance, we use 10-fold
cross-validation.
.=</p>
<p>‚Ä¢ Problem: Results may depend upon the particular partition
into folds.
.=</p>
<p>Introduction Framework Experimental setup Results Conclusions 16.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>1. Evaluation criteria: Statistical test
.=</p>
<p>‚Ä¢ For lower-variance estimate of performance, we use 10-fold
cross-validation.
.=</p>
<p>‚Ä¢ Problem: Results may depend upon the particular partition
into folds.
.=</p>
<p>‚Ä¢ We average over multiple cross-validation runs.
‚Ä¢ We can then compute 95% confidence interval by assuming a
t-distribution of these averages [Witten & Frank 2000].
.=</p>
<p>Introduction Framework Experimental setup Results Conclusions 16.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>2. Experimental data
.=</p>
<p>‚Ä¢ Data from six experimental studies, plus a combined dataset:
‚Ä¢ SW94: 400 observations from [Stahl & Wilson 1994]
‚Ä¢ SW95: 576 observations from [Stahl & Wilson 1995]
‚Ä¢ CGCB98: 1296 observations from [Costa-Gomes et al. 1998]
‚Ä¢ GH01: 500 observations from [Goeree & Holt 2001]
‚Ä¢ CVH03: 2992 observations from [Cooper & Van Huyck 2003]
‚Ä¢ RPC09: 1210 observations from [Rogers et al. 2009]
‚Ä¢ ALL6: All 6974 observations
.=</p>
<p>‚Ä¢ Subjects played 2-player normal form games once each.
‚Ä¢ Each action by an individual player is a single observation.
.=</p>
<p>Introduction Framework Experimental setup Results Conclusions 17.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Model comparisons: Nash equilibrium vs. BGT
.=</p>
<p>1035
UNEE
NNEE
.=</p>
<p>1030 Best BGT
Worst BGT
.=</p>
<p>1025
.=</p>
<p>1020
.=</p>
<p>1015
.=</p>
<p>1010
.=</p>
<p>105
.=</p>
<p>100
ALL6 SW94 SW95 CGCB98 GH01 CVH03 RPC09
.=</p>
<p>‚Ä¢ UNEE worse than every BGT model (except GH01 and SW95).
‚Ä¢ Even NNEE worse than QLk and QRE in most datasets.
‚Ä¢ BGT models typically predict human behavior better than
.=</p>
<p>Nash equilibrium-based models.
Introduction Framework Experimental setup Results Conclusions 18
.=</p>
<p>Likelihood improvement over uniform distribution.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Model comparisons: Lk and CH vs. QRE
.=</p>
<p>1035
Lk
.=</p>
<p>Poisson-CH
1030 QRE
.=</p>
<p>1025
.=</p>
<p>1020
.=</p>
<p>1015
.=</p>
<p>1010
.=</p>
<p>105
.=</p>
<p>100
ALL6 SW94 SW95 CGCB98 GH01 CVH03 RPC09
.=</p>
<p>‚Ä¢ Lk and Poisson-CH performance roughly similar.
‚Ä¢ No ordering between Lk/Poisson-CH and QRE.
‚Ä¢ Iterative models and quantal response appear to capture
.=</p>
<p>distinct phenomena.
Introduction Framework Experimental setup Results Conclusions 19
.=</p>
<p>Likelihood improvement over uniform distribution.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Model comparisons: QLk
.=</p>
<p>1035
QLk
.=</p>
<p>Best non-QLk
1030 Worst non-QLk
.=</p>
<p>1025
.=</p>
<p>1020
.=</p>
<p>1015
.=</p>
<p>1010
.=</p>
<p>105
.=</p>
<p>100
ALL6 SW94 SW95 CGCB98 GH01 CVH03 RPC09
.=</p>
<p>‚Ä¢ We would expect a model with both iterative and quantal
response components to perform best.
.=</p>
<p>‚Ä¢ That is the case: QLk is the best predictive model on almost
every dataset.
.=</p>
<p>Introduction Framework Experimental setup Results Conclusions 20
.=</p>
<p>Likelihood improvement over uniform distribution.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Deeper analysis
.=</p>
<p>1 Is the Poisson distribution helpful in cognitive hierarchy?
.=</p>
<p>2 Are higher-level agents helpful in level-k?
.=</p>
<p>3 Does payoff scaling matter in QRE?
.=</p>
<p>4 Is heterogeneity necessary in QLk?
.=</p>
<p>Introduction Framework Experimental setup Results Conclusions 21.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Heterogeneity
.=</p>
<p>In QLk, different agent levels:
.=</p>
<p>‚Ä¢ have different precisions (Œªk).
‚Ä¢ have different beliefs about the relative proportions of other
.=</p>
<p>levels.
‚Ä¢ Level-k believes that 100% of the population is level-(k ‚àí 1).
.=</p>
<p>‚Ä¢ have different beliefs about the precisions of other levels
(¬µk,`).
.=</p>
<p>œÄQLki ,0 (ai ) = |A |
‚àí1
.=</p>
<p>i ,
.=</p>
<p>œÄQLki ,1 = QBRi (œÄ
QLk
‚àíi ,0 | Œª1),
.=</p>
<p>œÄQLki ,2 = QBRi (Œ≥ | Œª2).
.=</p>
<p>Introduction Framework Experimental setup Results Conclusions 22.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Simplified hybrid model
.=</p>
<p>Question 4: Is heterogeneity necessary in QLk?
.=</p>
<p>‚Ä¢ Combine quantal response of QLk with truncated true beliefs
of cognitive hierarchy
.=</p>
<p>‚Ä¢ In quantal cognitive hierarchy model (QCH), all agent levels:
‚Ä¢ respond quantally (as in QLk).
‚Ä¢ respond to truncated, true distribution of lower levels (as in
.=</p>
<p>cognitive hierarchy).
‚Ä¢ have the same precision Œª.
‚Ä¢ are aware of the true precision of lower levels.
.=</p>
<p>œÄQCH ‚àí1i ,0 (ai ) = |Ai | ( )
m‚àë‚àí1
.=</p>
<p>œÄQCHi ,m (ai ) = QBR Œ±
QCH
.=</p>
<p>i `œÄj ,` | Œª
`=0
.=</p>
<p>Introduction Framework Experimental setup Results Conclusions 23.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>QCH vs. QLk
.=</p>
<p>1035
QLk
.=</p>
<p>QCH
1030
.=</p>
<p>1025
.=</p>
<p>1020
.=</p>
<p>1015
.=</p>
<p>1010
.=</p>
<p>105
.=</p>
<p>100
ALL6 SW94 SW95 CGCB98 GH01 CVH03 RPC09
.=</p>
<p>‚Ä¢ QCH predicts somewhat better than QLk on most datasets,
including the combined dataset.
.=</p>
<p>‚Ä¢ A less heterogeneous model has roughly the same predictive
power as QLk.
.=</p>
<p>Introduction Framework Experimental setup Results Conclusions 24
.=</p>
<p>Likelihood improvement over uniform distribution.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Summary
.=</p>
<p>1035
UNEE
NNEE
.=</p>
<p>1030 Lk
Poisson-CH
.=</p>
<p>QRE
25 QLk10 QCH
.=</p>
<p>1020
.=</p>
<p>1015
.=</p>
<p>1010
.=</p>
<p>105
.=</p>
<p>100
ALL6 SW94 SW95 CGCB98 GH01 CVH03 RPC09
.=</p>
<p>‚Ä¢ We compared predictive performance of four BGT models.
‚Ä¢ BGT models typically predict human behavior better than
.=</p>
<p>Nash equilibrium-based models.
‚Ä¢ Recommended specific models: QLk or QCH.
.=</p>
<p>Introduction Framework Experimental setup Results Conclusions 25
.=</p>
<p>Likelihood improvement over uniform distribution.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Thank you!
.=</p>
<p>1035
UNEE
NNEE
.=</p>
<p>1030 Lk
Poisson-CH
.=</p>
<p>QRE
.=</p>
<p>1025
QLk
.=</p>
<p>QCH
.=</p>
<p>1020
.=</p>
<p>1015
.=</p>
<p>1010
.=</p>
<p>105
.=</p>
<p>100
ALL6 SW94 SW95 CGCB98 GH01 CVH03 RPC09
.=</p>
<p>‚Ä¢ We compared predictive performance of four BGT models.
‚Ä¢ BGT models typically predict human behavior better than
.=</p>
<p>Nash equilibrium-based models.
‚Ä¢ Recommended specific models: QLk or QCH.
.=</p>
<p>Introduction Framework Experimental setup Results Conclusions 26
.=</p>
<p>Likelihood improvement over uniform distribution.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Previous work
.=</p>
<p>Paper
.=</p>
<p>[Stahl and Wilson, 1994] t t
[McKelvey and Palfrey, 1995] f f
[Stahl and Wilson, 1995] f t
[Costa-Gomes et al., 1998] f f
[Haruvy et al., 1999] t
[Costa-Gomes et al., 2001] f f
[Haruvy et al., 2001] t
[Morgan and Sefton, 2002] f p
[WeizsaÃàcker, 2003] t t
[Camerer et al., 2004] f p
[Costa-Gomes and Crawford, 2006] f f
[Stahl and Haruvy, 2008] t
[Rey-Biel, 2009] t t
[Georganas et al., 2010] f f
[Hahn et al., 2010] p
.=</p>
<p>[Camerer et al., 2001] f f
[Chong et al., 2005] f p p
[Crawford and Iriberri, 2007] p p p
[Costa-Gomes et al., 2009] f f f f
[Rogers et al., 2009] f f f
.=</p>
<p>A ‚Äòp‚Äô indicates that the study evaluated out-of-sample prediction performance for that model; a ‚Äòt‚Äô indicates
statistical tests of training sample performance; an ‚Äòf‚Äô indicates comparison of training sample fit only.
Only five studies compared more than one of the non-Nash models we considered.
.=</p>
<p>Appendix 27
.=</p>
<p>Nash
.=</p>
<p>QLk
.=</p>
<p>Lk
.=</p>
<p>CH
.=</p>
<p>QRE.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Bibliography
.=</p>
<p>Camerer, C., Ho, T., and Chong, J. (2001).
Behavioral game theory: Thinking, learning, and teaching.
Nobel Symposium on Behavioral and Experimental Economics.
.=</p>
<p>Camerer, C., Ho, T., and Chong, J. (2004).
A cognitive hierarchy model of games.
QJE, 119(3):861‚Äì898.
.=</p>
<p>Chong, J., Camerer, C., and Ho, T. (2005).
Cognitive hierarchy: A limited thinking theory in games.
Experimental Business Research, Vol. III: Marketing,
accounting and cognitive perspectives, pages 203‚Äì228.
.=</p>
<p>Costa-Gomes, M. and Crawford, V. (2006).
Cognition and behavior in two-person guessing games: An
experimental study.
AER, 96(5):1737‚Äì1768.
.=</p>
<p>Appendix 28
Costa-Gomes, M., Crawford, V., and Broseta, B. (1998).
Cognition and behavior in normal-form games: an
experimental study.
Discussion paper 98-22, UCSD.
.=</p>
<p>Costa-Gomes, M., Crawford, V., and Broseta, B. (2001).
Cognition and behavior in normal-form games: An
experimental study.
Econometrica, 69(5):1193‚Äì1235.
.=</p>
<p>Costa-Gomes, M., Crawford, V., and Iriberri, N. (2009).
Comparing models of strategic thinking in Van Huyck,
Battalio, and Beil‚Äôs coordination games.
JEEA, 7(2-3):365‚Äì376.
.=</p>
<p>Crawford, V. and Iriberri, N. (2007).
Fatal attraction: Salience, naivete, and sophistication in
experimental ‚Äúhide-and-seek‚Äù games.
AER, 97(5):1731‚Äì1750.
.=</p>
<p>Georganas, S., Healy, P. J., and Weber, R. (2010).
On the persistence of strategic sophistication.
Working paper, University of Bonn.
.=</p>
<p>Hahn, P. R., Lum, K., and Mela, C. (2010).
A semiparametric model for assessing cognitive hierarchy
theories of beauty contest games.
Working paper, Duke University.
.=</p>
<p>Haruvy, E., Stahl, D., and Wilson, P. (1999).
Evidence for optimistic and pessimistic behavior in
normal-form games.
Economics Letters, 63(3):255‚Äì259.
.=</p>
<p>Haruvy, E., Stahl, D., and Wilson, P. (2001).
Modeling and testing for heterogeneity in observed strategic
behavior.
Review of Economics and Statistics, 83(1):146‚Äì157.
.=</p>
<p>McKelvey, R. and Palfrey, T. (1995).
Quantal response equilibria for normal form games.
GEB, 10(1):6‚Äì38.
.=</p>
<p>Morgan, J. and Sefton, M. (2002).
An experimental investigation of unprofitable games.
GEB, 40(1):123‚Äì146.
.=</p>
<p>Rey-Biel, P. (2009).
Equilibrium play and best response to (stated) beliefs in
normal form games.
GEB, 65(2):572‚Äì585.
.=</p>
<p>Rogers, B. W., Palfrey, T. R., and Camerer, C. F. (2009).
Heterogeneous quantal response equilibrium and cognitive
hierarchies.
JET, 144(4):1440‚Äì1467.
.=</p>
<p>Stahl, D. and Haruvy, E. (2008).
Level-n bounded rationality and dominated strategies in
normal-form games.
JEBO, 66(2):226‚Äì232.
.=</p>
<p>Stahl, D. and Wilson, P. (1994).
Experimental evidence on players‚Äô models of other players.
JEBO, 25(3):309‚Äì327.
.=</p>
<p>Stahl, D. and Wilson, P. (1995).
On players‚Äô models of other players: Theory and experimental
evidence.
GEB, 10(1):218‚Äì254.
.=</p>
<p>WeizsaÃàcker, G. (2003).
Ignoring the rationality of others: evidence from experimental
normal-form games.
GEB, 44(1):145‚Äì171..=</p>
</div>
</body>
		<back>
			<div type="references">

				<listBibl>


				</listBibl>
			</div>
		</back>
	</text>
</TEI>
