<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /mnt/sda1/Dissertation/grobid/grobid-0.5.6/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Multi-agent reinforcement learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2019-12-22">December 22, 2019</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Schnebli</forename><surname>Zoltan</surname></persName>
						</author>
						<title level="a" type="main">Multi-agent reinforcement learning</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2019-12-22">December 22, 2019</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.5.6" ident="GROBID" when="2019-12-24T15:31+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Time-Bounded
Sequential Parameter Optimization
.=</p>
<p>Frank Hutter, Holger H. Hoos,
Kevin Leyton-Brown, Kevin P. Murphy
.=</p>
<p>Department of Computer Science
University of British Columbia
.=</p>
<p>Canada
{hutter, hoos, kevinlb, murphyk}@cs.ubc.ca.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>I E.g. local search
.=</p>
<p>– neighbourhoods, restarts, types of perturbations, tabu length
(or range for it), etc
.=</p>
<p>I E.g., tree search
.=</p>
<p>– Branching heuristics, no-good learning, restarts,
pre-processing, etc
.=</p>
<p>Automatically find good instantiation of parameters
I Eliminate most tedious part of algorithm design and end use
.=</p>
<p>I Save development time & improve performance
.=</p>
<p>Automated Parameter Optimization
.=</p>
<p>Most algorithms have parameters
.=</p>
<p>I Decisions that are left open during algorithm design
.=</p>
<p>I Instantiate to optimize empirical performance
.=</p>
<p>2.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>I E.g., tree search
.=</p>
<p>– Branching heuristics, no-good learning, restarts,
pre-processing, etc
.=</p>
<p>Automatically find good instantiation of parameters
I Eliminate most tedious part of algorithm design and end use
.=</p>
<p>I Save development time & improve performance
.=</p>
<p>Automated Parameter Optimization
.=</p>
<p>Most algorithms have parameters
.=</p>
<p>I Decisions that are left open during algorithm design
.=</p>
<p>I Instantiate to optimize empirical performance
I E.g. local search
.=</p>
<p>– neighbourhoods, restarts, types of perturbations, tabu length
(or range for it), etc
.=</p>
<p>2.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Automatically find good instantiation of parameters
I Eliminate most tedious part of algorithm design and end use
.=</p>
<p>I Save development time & improve performance
.=</p>
<p>Automated Parameter Optimization
.=</p>
<p>Most algorithms have parameters
.=</p>
<p>I Decisions that are left open during algorithm design
.=</p>
<p>I Instantiate to optimize empirical performance
I E.g. local search
.=</p>
<p>– neighbourhoods, restarts, types of perturbations, tabu length
(or range for it), etc
.=</p>
<p>I E.g., tree search
.=</p>
<p>– Branching heuristics, no-good learning, restarts,
pre-processing, etc
.=</p>
<p>2.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Automated Parameter Optimization
.=</p>
<p>Most algorithms have parameters
.=</p>
<p>I Decisions that are left open during algorithm design
.=</p>
<p>I Instantiate to optimize empirical performance
I E.g. local search
.=</p>
<p>– neighbourhoods, restarts, types of perturbations, tabu length
(or range for it), etc
.=</p>
<p>I E.g., tree search
.=</p>
<p>– Branching heuristics, no-good learning, restarts,
pre-processing, etc
.=</p>
<p>Automatically find good instantiation of parameters
I Eliminate most tedious part of algorithm design and end use
.=</p>
<p>I Save development time & improve performance
.=</p>
<p>2.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>I Categorical parameters
.=</p>
<p>– Racing algorithms, F-Race [Birattari et al., ’02-present]
– Iterated Local Search, ParamILS [Hutter et al., AAAI ’07 & JAIR’09]
.=</p>
<p>I Success of parameter optimization
.=</p>
<p>– Many parameters (e.g., CPLEX with 63 parameters)
– Large speedups (sometimes orders of magnitude!)
– For many problems: SAT, MIP, time-tabling, protein folding, ...
.=</p>
<p>Parameter Optimization Methods
.=</p>
<p>I Lots of work on numerical parameters, e.g.
.=</p>
<p>– CALIBRA [Adenso-Diaz & Laguna, ’06]
– Population-based, e.g. CMA-ES [Hansen et al, ’95-present]
.=</p>
<p>3.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>I Success of parameter optimization
.=</p>
<p>– Many parameters (e.g., CPLEX with 63 parameters)
– Large speedups (sometimes orders of magnitude!)
– For many problems: SAT, MIP, time-tabling, protein folding, ...
.=</p>
<p>Parameter Optimization Methods
.=</p>
<p>I Lots of work on numerical parameters, e.g.
.=</p>
<p>– CALIBRA [Adenso-Diaz & Laguna, ’06]
– Population-based, e.g. CMA-ES [Hansen et al, ’95-present]
.=</p>
<p>I Categorical parameters
.=</p>
<p>– Racing algorithms, F-Race [Birattari et al., ’02-present]
– Iterated Local Search, ParamILS [Hutter et al., AAAI ’07 & JAIR’09]
.=</p>
<p>3.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Parameter Optimization Methods
.=</p>
<p>I Lots of work on numerical parameters, e.g.
.=</p>
<p>– CALIBRA [Adenso-Diaz & Laguna, ’06]
– Population-based, e.g. CMA-ES [Hansen et al, ’95-present]
.=</p>
<p>I Categorical parameters
.=</p>
<p>– Racing algorithms, F-Race [Birattari et al., ’02-present]
– Iterated Local Search, ParamILS [Hutter et al., AAAI ’07 & JAIR’09]
.=</p>
<p>I Success of parameter optimization
.=</p>
<p>– Many parameters (e.g., CPLEX with 63 parameters)
– Large speedups (sometimes orders of magnitude!)
– For many problems: SAT, MIP, time-tabling, protein folding, ...
.=</p>
<p>3.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>I But sometimes we would like to know more
.=</p>
<p>– How important is each of the parameters?
– Which parameters interact?
– For which types of instances is a parameter setting good?
 Inform algorithm designer
.=</p>
<p>Response surface models can help
I Predictive models of algorithm performance with given
.=</p>
<p>parameter settings
.=</p>
<p>Limitations of Model-Free Parameter
Optimization
.=</p>
<p>Model-free methods only return the best parameter setting
I Often that is all you need
.=</p>
<p>– E.g.: end user can customize algorithm
.=</p>
<p>4.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Response surface models can help
I Predictive models of algorithm performance with given
.=</p>
<p>parameter settings
.=</p>
<p>Limitations of Model-Free Parameter
Optimization
.=</p>
<p>Model-free methods only return the best parameter setting
I Often that is all you need
.=</p>
<p>– E.g.: end user can customize algorithm
.=</p>
<p>I But sometimes we would like to know more
.=</p>
<p>– How important is each of the parameters?
– Which parameters interact?
– For which types of instances is a parameter setting good?
 Inform algorithm designer
.=</p>
<p>4.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Limitations of Model-Free Parameter
Optimization
.=</p>
<p>Model-free methods only return the best parameter setting
I Often that is all you need
.=</p>
<p>– E.g.: end user can customize algorithm
.=</p>
<p>I But sometimes we would like to know more
.=</p>
<p>– How important is each of the parameters?
– Which parameters interact?
– For which types of instances is a parameter setting good?
 Inform algorithm designer
.=</p>
<p>Response surface models can help
I Predictive models of algorithm performance with given
.=</p>
<p>parameter settings
.=</p>
<p>4.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>I Studied SPO components [Hutter et al, GECCO-09]
I Want completely automated tool
 More robust version: SPO+
.=</p>
<p>I This work: TB-SPO, reduce computational overheads
I Ongoing work: extend TB-SPO to handle
.=</p>
<p>– Categorical parameters
– Multiple benchmark instances
– Very promising results for both
.=</p>
<p>Sequential Parameter Optimization (SPO)
.=</p>
<p>I Original SPO [Bartz-Beielstein et al., ’05-present]
I SPO toolbox
I Set of interactive tools for parameter optimization
.=</p>
<p>5.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>I This work: TB-SPO, reduce computational overheads
I Ongoing work: extend TB-SPO to handle
.=</p>
<p>– Categorical parameters
– Multiple benchmark instances
– Very promising results for both
.=</p>
<p>Sequential Parameter Optimization (SPO)
.=</p>
<p>I Original SPO [Bartz-Beielstein et al., ’05-present]
I SPO toolbox
I Set of interactive tools for parameter optimization
.=</p>
<p>I Studied SPO components [Hutter et al, GECCO-09]
I Want completely automated tool
 More robust version: SPO+
.=</p>
<p>5.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>I Ongoing work: extend TB-SPO to handle
.=</p>
<p>– Categorical parameters
– Multiple benchmark instances
– Very promising results for both
.=</p>
<p>Sequential Parameter Optimization (SPO)
.=</p>
<p>I Original SPO [Bartz-Beielstein et al., ’05-present]
I SPO toolbox
I Set of interactive tools for parameter optimization
.=</p>
<p>I Studied SPO components [Hutter et al, GECCO-09]
I Want completely automated tool
 More robust version: SPO+
.=</p>
<p>I This work: TB-SPO, reduce computational overheads
.=</p>
<p>5.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>– Very promising results for both
.=</p>
<p>Sequential Parameter Optimization (SPO)
.=</p>
<p>I Original SPO [Bartz-Beielstein et al., ’05-present]
I SPO toolbox
I Set of interactive tools for parameter optimization
.=</p>
<p>I Studied SPO components [Hutter et al, GECCO-09]
I Want completely automated tool
 More robust version: SPO+
.=</p>
<p>I This work: TB-SPO, reduce computational overheads
I Ongoing work: extend TB-SPO to handle
.=</p>
<p>– Categorical parameters
– Multiple benchmark instances
.=</p>
<p>5.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Sequential Parameter Optimization (SPO)
.=</p>
<p>I Original SPO [Bartz-Beielstein et al., ’05-present]
I SPO toolbox
I Set of interactive tools for parameter optimization
.=</p>
<p>I Studied SPO components [Hutter et al, GECCO-09]
I Want completely automated tool
 More robust version: SPO+
.=</p>
<p>I This work: TB-SPO, reduce computational overheads
I Ongoing work: extend TB-SPO to handle
.=</p>
<p>– Categorical parameters
– Multiple benchmark instances
– Very promising results for both
.=</p>
<p>5.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Outline
.=</p>
<p>1. Sequential Model-Based Optimization
.=</p>
<p>2. Reducing the Computational Overhead Due To Models
.=</p>
<p>3. Conclusions
.=</p>
<p>6.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Outline
.=</p>
<p>1. Sequential Model-Based Optimization
.=</p>
<p>2. Reducing the Computational Overhead Due To Models
.=</p>
<p>3. Conclusions
.=</p>
<p>7.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>0. Run algorithm with initial parameter settings
1. Fit a model to the data
2. Use model to pick promising parameter setting
3. Perform an algorithm run with that parameter setting
I Repeat 1-3 until time is up
.=</p>
<p>First step
.=</p>
<p>Sequential Model-Based Optimization
(SMBO)
Blackbox function optimization; function = algo. performance
.=</p>
<p>30  
.=</p>
<p>.
.=</p>
<p>.
25 True function
.=</p>
<p>.
.=</p>
<p>.
20
.=</p>
<p>15
.=</p>
<p>10
.=</p>
<p>5
.=</p>
<p>0
.=</p>
<p>−5  
0 0.2 0.4 0.6 0.8 1
.=</p>
<p>parameter x
.=</p>
<p>8
.=</p>
<p>response y.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>1. Fit a model to the data
2. Use model to pick promising parameter setting
3. Perform an algorithm run with that parameter setting
I Repeat 1-3 until time is up
.=</p>
<p>First step
.=</p>
<p>Sequential Model-Based Optimization
(SMBO)
Blackbox function optimization; function = algo. performance
.=</p>
<p>0. Run algorithm with initial parameter settings
.=</p>
<p>30  
.=</p>
<p>.
.=</p>
<p>25 True function
.=</p>
<p>Function evaluations
.=</p>
<p>.
20
.=</p>
<p>15
.=</p>
<p>10
.=</p>
<p>5
.=</p>
<p>0
.=</p>
<p>−5  
0 0.2 0.4 0.6 0.8 1
.=</p>
<p>parameter x
.=</p>
<p>8
.=</p>
<p>response y.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>1. Fit a model to the data
2. Use model to pick promising parameter setting
3. Perform an algorithm run with that parameter setting
I Repeat 1-3 until time is up
.=</p>
<p>First step
.=</p>
<p>Sequential Model-Based Optimization
(SMBO)
Blackbox function optimization; function = algo. performance
.=</p>
<p>0. Run algorithm with initial parameter settings
.=</p>
<p>30  
.=</p>
<p>.
.=</p>
<p>.
25 .
.=</p>
<p>Function evaluations
.=</p>
<p>.
20
.=</p>
<p>15
.=</p>
<p>10
.=</p>
<p>5
.=</p>
<p>0
.=</p>
<p>−5  
0 0.2 0.4 0.6 0.8 1
.=</p>
<p>parameter x
.=</p>
<p>8
.=</p>
<p>response y.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>2. Use model to pick promising parameter setting
3. Perform an algorithm run with that parameter setting
I Repeat 1-3 until time is up
.=</p>
<p>First step
.=</p>
<p>Sequential Model-Based Optimization
(SMBO)
Blackbox function optimization; function = algo. performance
.=</p>
<p>0. Run algorithm with initial parameter settings
1. Fit a model to the data
.=</p>
<p>30  
.=</p>
<p>DACE mean prediction
.=</p>
<p>DACE mean +/− 2*stddev
25 .
.=</p>
<p>Function evaluations
.=</p>
<p>.
20
.=</p>
<p>15
.=</p>
<p>10
.=</p>
<p>5
.=</p>
<p>0
.=</p>
<p>−5  
0 0.2 0.4 0.6 0.8 1
.=</p>
<p>parameter x
.=</p>
<p>8
.=</p>
<p>response y.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>3. Perform an algorithm run with that parameter setting
I Repeat 1-3 until time is up
.=</p>
<p>First step
.=</p>
<p>Sequential Model-Based Optimization
(SMBO)
Blackbox function optimization; function = algo. performance
.=</p>
<p>0. Run algorithm with initial parameter settings
1. Fit a model to the data
2. Use model to pick promising parameter setting
.=</p>
<p>30  
.=</p>
<p>DACE mean prediction
.=</p>
<p>DACE mean +/− 2*stddev
25 .
.=</p>
<p>Function evaluations
.=</p>
<p>EI (scaled)
20
.=</p>
<p>15
.=</p>
<p>10
.=</p>
<p>5
.=</p>
<p>0
.=</p>
<p>−5  
0 0.2 0.4 0.6 0.8 1
.=</p>
<p>parameter x
.=</p>
<p>8
.=</p>
<p>response y.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>I Repeat 1-3 until time is up
.=</p>
<p>First step
.=</p>
<p>Sequential Model-Based Optimization
(SMBO)
Blackbox function optimization; function = algo. performance
.=</p>
<p>0. Run algorithm with initial parameter settings
1. Fit a model to the data
2. Use model to pick promising parameter setting
3. Perform an algorithm run with that parameter setting
.=</p>
<p>30  
.=</p>
<p>DACE mean prediction
.=</p>
<p>DACE mean +/− 2*stddev
25 True function
.=</p>
<p>Function evaluations
.=</p>
<p>EI (scaled)
20
.=</p>
<p>15
.=</p>
<p>10
.=</p>
<p>5
.=</p>
<p>0
.=</p>
<p>−5  
0 0.2 0.4 0.6 0.8 1
.=</p>
<p>parameter x
.=</p>
<p>8
.=</p>
<p>response y.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Sequential Model-Based Optimization
(SMBO)
Blackbox function optimization; function = algo. performance
.=</p>
<p>0. Run algorithm with initial parameter settings
1. Fit a model to the data
2. Use model to pick promising parameter setting
3. Perform an algorithm run with that parameter setting
I Repeat 1-3 until time is up
.=</p>
<p>30  30  
.=</p>
<p>DACE mean prediction DACE mean prediction
.=</p>
<p>DACE mean +/− 2*stddev DACE mean +/− 2*stddev
25 True function 25 True function
.=</p>
<p>Function evaluations Function evaluations
.=</p>
<p>EI (scaled) EI (scaled)
20 20
.=</p>
<p>15 15
.=</p>
<p>10 10
.=</p>
<p>5 5
.=</p>
<p>0 0
.=</p>
<p>−5  −5  
0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1
.=</p>
<p>parameter x parameter x
.=</p>
<p>First step Second step
8
.=</p>
<p>response y
.=</p>
<p>response y.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>1000s
50s
.=</p>
<p>20s
10s
.=</p>
<p>Computational Overhead due to Models:
Example
Example times
.=</p>
<p>0. Run algorithm with initial parameter settings
1. Fit a model to the data
2. Use model to pick promising parameter setting
3. Perform an algorithm run with that parameter setting
I Repeat 1-3 until time is up
.=</p>
<p>30  30  
.=</p>
<p>DACE mean prediction DACE mean prediction
.=</p>
<p>DACE mean +/− 2*stddev DACE mean +/− 2*stddev
25 True function 25 True function
.=</p>
<p>Function evaluations Function evaluations
.=</p>
<p>EI (scaled) EI (scaled)
20 20
.=</p>
<p>15 15
.=</p>
<p>10 10
.=</p>
<p>5 5
.=</p>
<p>0 0
.=</p>
<p>−5  −5  
0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1
.=</p>
<p>parameter x parameter x
.=</p>
<p>First step Second step
9
.=</p>
<p>response y
.=</p>
<p>response y.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>50s
20s
.=</p>
<p>10s
.=</p>
<p>Computational Overhead due to Models:
Example
Example times
.=</p>
<p>0. Run algorithm with initial parameter settings 1000s
1. Fit a model to the data
2. Use model to pick promising parameter setting
3. Perform an algorithm run with that parameter setting
I Repeat 1-3 until time is up
.=</p>
<p>30  30  
.=</p>
<p>DACE mean prediction DACE mean prediction
.=</p>
<p>DACE mean +/− 2*stddev DACE mean +/− 2*stddev
25 True function 25 True function
.=</p>
<p>Function evaluations Function evaluations
.=</p>
<p>EI (scaled) EI (scaled)
20 20
.=</p>
<p>15 15
.=</p>
<p>10 10
.=</p>
<p>5 5
.=</p>
<p>0 0
.=</p>
<p>−5  −5  
0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1
.=</p>
<p>parameter x parameter x
.=</p>
<p>First step Second step
9
.=</p>
<p>response y
.=</p>
<p>response y.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>20s
10s
.=</p>
<p>Computational Overhead due to Models:
Example
Example times
.=</p>
<p>0. Run algorithm with initial parameter settings 1000s
1. Fit a model to the data 50s
2. Use model to pick promising parameter setting
3. Perform an algorithm run with that parameter setting
I Repeat 1-3 until time is up
.=</p>
<p>30  30  
.=</p>
<p>DACE mean prediction DACE mean prediction
.=</p>
<p>DACE mean +/− 2*stddev DACE mean +/− 2*stddev
25 True function 25 True function
.=</p>
<p>Function evaluations Function evaluations
.=</p>
<p>EI (scaled) EI (scaled)
20 20
.=</p>
<p>15 15
.=</p>
<p>10 10
.=</p>
<p>5 5
.=</p>
<p>0 0
.=</p>
<p>−5  −5  
0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1
.=</p>
<p>parameter x parameter x
.=</p>
<p>First step Second step
9
.=</p>
<p>response y
.=</p>
<p>response y.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>10s
.=</p>
<p>Computational Overhead due to Models:
Example
Example times
.=</p>
<p>0. Run algorithm with initial parameter settings 1000s
1. Fit a model to the data 50s
2. Use model to pick promising parameter setting 20s
3. Perform an algorithm run with that parameter setting
I Repeat 1-3 until time is up
.=</p>
<p>30  30  
.=</p>
<p>DACE mean prediction DACE mean prediction
.=</p>
<p>DACE mean +/− 2*stddev DACE mean +/− 2*stddev
25 True function 25 True function
.=</p>
<p>Function evaluations Function evaluations
.=</p>
<p>EI (scaled) EI (scaled)
20 20
.=</p>
<p>15 15
.=</p>
<p>10 10
.=</p>
<p>5 5
.=</p>
<p>0 0
.=</p>
<p>−5  −5  
0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1
.=</p>
<p>parameter x parameter x
.=</p>
<p>First step Second step
9
.=</p>
<p>response y
.=</p>
<p>response y.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Computational Overhead due to Models:
Example
Example times
.=</p>
<p>0. Run algorithm with initial parameter settings 1000s
1. Fit a model to the data 50s
2. Use model to pick promising parameter setting 20s
3. Perform an algorithm run with that parameter setting 10s
I Repeat 1-3 until time is up
.=</p>
<p>30  30  
.=</p>
<p>DACE mean prediction DACE mean prediction
.=</p>
<p>DACE mean +/− 2*stddev DACE mean +/− 2*stddev
25 True function 25 True function
.=</p>
<p>Function evaluations Function evaluations
.=</p>
<p>EI (scaled) EI (scaled)
20 20
.=</p>
<p>15 15
.=</p>
<p>10 10
.=</p>
<p>5 5
.=</p>
<p>0 0
.=</p>
<p>−5  −5  
0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1
.=</p>
<p>parameter x parameter x
.=</p>
<p>First step Second step
9
.=</p>
<p>response y
.=</p>
<p>response y.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Outline
.=</p>
<p>1. Sequential Model-Based Optimization
.=</p>
<p>2. Reducing the Computational Overhead Due To Models
Do More Algorithm Runs To Bound Model Overhead
Using a Cheaper (and Better!) Model
.=</p>
<p>3. Conclusions
.=</p>
<p>10.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Outline
.=</p>
<p>1. Sequential Model-Based Optimization
.=</p>
<p>2. Reducing the Computational Overhead Due To Models
Do More Algorithm Runs To Bound Model Overhead
Using a Cheaper (and Better!) Model
.=</p>
<p>3. Conclusions
.=</p>
<p>11.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>I Our solution: simply drop the initial design
I Instead: interleave random settings during the search
I Much better anytime performance
.=</p>
<p>Removing the costly initial design (phase 0)
.=</p>
<p>I How to choose number of param. settings in initial design?
I Too large: take too long to evaluate all of the settings
I Too small: poor first model, might not recover
.=</p>
<p>12.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Removing the costly initial design (phase 0)
.=</p>
<p>I How to choose number of param. settings in initial design?
I Too large: take too long to evaluate all of the settings
I Too small: poor first model, might not recover
.=</p>
<p>I Our solution: simply drop the initial design
I Instead: interleave random settings during the search
I Much better anytime performance
.=</p>
<p>12.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Solution 1
.=</p>
<p>I Do more algorithm runs to bound model overhead
.=</p>
<p>– Select not one but many promising points (little overhead)
– Perform runs for at least as long as phases 1 and 2 took
.=</p>
<p>Overhead due to Models
.=</p>
<p>Central SMBO algorithm loop
.=</p>
<p>I Repeat: Example times
.=</p>
<p>1. Fit model using performance data gathered so far 50s
2. Use model to select promising parameter setting 20s
3. Perform algorithm run(s) with that parameter setting 10s
.=</p>
<p> Only small fraction of time spent actually running algorithms
.=</p>
<p>13.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Overhead due to Models
.=</p>
<p>Central SMBO algorithm loop
.=</p>
<p>I Repeat: Example times
.=</p>
<p>1. Fit model using performance data gathered so far 50s
2. Use model to select promising parameter setting 20s
3. Perform algorithm run(s) with that parameter setting 10s
.=</p>
<p> Only small fraction of time spent actually running algorithms
.=</p>
<p>Solution 1
.=</p>
<p>I Do more algorithm runs to bound model overhead
.=</p>
<p>– Select not one but many promising points (little overhead)
– Perform runs for at least as long as phases 1 and 2 took
.=</p>
<p>13.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>– Use mechanism from SPO+:
– Incrementally perform runs for θ until either
.=</p>
<p>+ Empirical performance for θ worse than for θinc  drop θ
+ Performed as many runs for θ as for θinc  θ becomes new θinc
.=</p>
<p>Algorithms
I TB-SPO
.=</p>
<p>– Get ordered list of promising parameter settings using model
– Interleave random settings: 2nd, 4th, etc
– Compare one param. setting at a time to incumbent
– Nice side effect: additional runs on good random settings
.=</p>
<p>I “Strawman” algorithm: TB-Random
.=</p>
<p>– Only use random settings
– Compare one param. setting at a time to incumbent
.=</p>
<p>Which Setting to Perform How Many Runs for
.=</p>
<p>Heuristic Mechanism
I Compare one configuration θ at a time to the incumbent θinc
.=</p>
<p>I Stop once time bound is reached
.=</p>
<p>14.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>– Incrementally perform runs for θ until either
.=</p>
<p>+ Empirical performance for θ worse than for θinc  drop θ
+ Performed as many runs for θ as for θinc  θ becomes new θinc
.=</p>
<p>Algorithms
I TB-SPO
.=</p>
<p>– Get ordered list of promising parameter settings using model
– Interleave random settings: 2nd, 4th, etc
– Compare one param. setting at a time to incumbent
– Nice side effect: additional runs on good random settings
.=</p>
<p>I “Strawman” algorithm: TB-Random
.=</p>
<p>– Only use random settings
– Compare one param. setting at a time to incumbent
.=</p>
<p>Which Setting to Perform How Many Runs for
.=</p>
<p>Heuristic Mechanism
I Compare one configuration θ at a time to the incumbent θinc
.=</p>
<p>– Use mechanism from SPO+:
.=</p>
<p>I Stop once time bound is reached
.=</p>
<p>14.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Algorithms
I TB-SPO
.=</p>
<p>– Get ordered list of promising parameter settings using model
– Interleave random settings: 2nd, 4th, etc
– Compare one param. setting at a time to incumbent
– Nice side effect: additional runs on good random settings
.=</p>
<p>I “Strawman” algorithm: TB-Random
.=</p>
<p>– Only use random settings
– Compare one param. setting at a time to incumbent
.=</p>
<p>Which Setting to Perform How Many Runs for
.=</p>
<p>Heuristic Mechanism
I Compare one configuration θ at a time to the incumbent θinc
.=</p>
<p>– Use mechanism from SPO+:
– Incrementally perform runs for θ until either
.=</p>
<p>+ Empirical performance for θ worse than for θinc  drop θ
+ Performed as many runs for θ as for θinc  θ becomes new θinc
.=</p>
<p>I Stop once time bound is reached
.=</p>
<p>14.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>– Compare one param. setting at a time to incumbent
– Nice side effect: additional runs on good random settings
.=</p>
<p>I “Strawman” algorithm: TB-Random
.=</p>
<p>– Only use random settings
– Compare one param. setting at a time to incumbent
.=</p>
<p>Which Setting to Perform How Many Runs for
.=</p>
<p>Heuristic Mechanism
I Compare one configuration θ at a time to the incumbent θinc
.=</p>
<p>– Use mechanism from SPO+:
– Incrementally perform runs for θ until either
.=</p>
<p>+ Empirical performance for θ worse than for θinc  drop θ
+ Performed as many runs for θ as for θinc  θ becomes new θinc
.=</p>
<p>I Stop once time bound is reached
.=</p>
<p>Algorithms
I TB-SPO
.=</p>
<p>– Get ordered list of promising parameter settings using model
– Interleave random settings: 2nd, 4th, etc
.=</p>
<p>14.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>I “Strawman” algorithm: TB-Random
.=</p>
<p>– Only use random settings
– Compare one param. setting at a time to incumbent
.=</p>
<p>Which Setting to Perform How Many Runs for
.=</p>
<p>Heuristic Mechanism
I Compare one configuration θ at a time to the incumbent θinc
.=</p>
<p>– Use mechanism from SPO+:
– Incrementally perform runs for θ until either
.=</p>
<p>+ Empirical performance for θ worse than for θinc  drop θ
+ Performed as many runs for θ as for θinc  θ becomes new θinc
.=</p>
<p>I Stop once time bound is reached
.=</p>
<p>Algorithms
I TB-SPO
.=</p>
<p>– Get ordered list of promising parameter settings using model
– Interleave random settings: 2nd, 4th, etc
– Compare one param. setting at a time to incumbent
– Nice side effect: additional runs on good random settings
.=</p>
<p>14.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Which Setting to Perform How Many Runs for
.=</p>
<p>Heuristic Mechanism
I Compare one configuration θ at a time to the incumbent θinc
.=</p>
<p>– Use mechanism from SPO+:
– Incrementally perform runs for θ until either
.=</p>
<p>+ Empirical performance for θ worse than for θinc  drop θ
+ Performed as many runs for θ as for θinc  θ becomes new θinc
.=</p>
<p>I Stop once time bound is reached
.=</p>
<p>Algorithms
I TB-SPO
.=</p>
<p>– Get ordered list of promising parameter settings using model
– Interleave random settings: 2nd, 4th, etc
– Compare one param. setting at a time to incumbent
– Nice side effect: additional runs on good random settings
.=</p>
<p>I “Strawman” algorithm: TB-Random
.=</p>
<p>– Only use random settings
– Compare one param. setting at a time to incumbent
.=</p>
<p>14.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>I Seven different SAT instances
.=</p>
<p>– 1 Quasigroups with holes (QWH) instance used previously
– 3 instances from Quasigroup completion (QCP)
– 3 instances from Graph colouring based on smallworld graphs
.=</p>
<p>(SWGCP)
.=</p>
<p>Experimental validation: setup
.=</p>
<p>I Optimizing SLS algorithm SAPS
.=</p>
<p>– Prominent SAT solver with 4 continuous parameters
– Previously used to evaluate parameter optimization approaches
.=</p>
<p>15.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Experimental validation: setup
.=</p>
<p>I Optimizing SLS algorithm SAPS
.=</p>
<p>– Prominent SAT solver with 4 continuous parameters
– Previously used to evaluate parameter optimization approaches
.=</p>
<p>I Seven different SAT instances
.=</p>
<p>– 1 Quasigroups with holes (QWH) instance used previously
– 3 instances from Quasigroup completion (QCP)
– 3 instances from Graph colouring based on smallworld graphs
.=</p>
<p>(SWGCP)
.=</p>
<p>15.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p> 
5
.=</p>
<p>10 SPO+
.=</p>
<p>TB−SPO (w/ LHD)
.=</p>
<p>TB−SPO
.=</p>
<p>4
10
.=</p>
<p> 
1 2 3
.=</p>
<p>10 10 10
CPU time t spent for configuration [s]
.=</p>
<p>TB-SPO with empty LHD
.=</p>
<p>Scenario SPO+ TB-SPO TB-Random pval1 pval2
.=</p>
<p>Saps-QCP-med [·10−2] 4.50± 0.31 4.32± 0.21 4.23 ± 0.15 4 · 10−3 0.17
Saps-QCP-q075 3.77± 9.72 0.19 ± 0.02 0.19 ± 0.01 2 · 10−6 0.78
Saps-QCP-q095 49.91± 0.00 2.20 ± 1.17 2.64± 1.24 1 · 10−10 0.12
Saps-QWH [·103] 10.7± 0.76 10.1± 0.58 9.88 ± 0.41 6 · 10−3 0.14
Saps-SWGCP-med 49.95± 0.00 0.18± 0.03 0.17 ± 0.02 1 · 10−10 0.37
Saps-SWGCP-q075 50± 0 0.24± 0.04 0.22 ± 0.03 1 · 10−10 0.08
Saps-SWGCP-q095 50± 0 0.25 ± 0.05 0.28± 0.10 1 · 10−10 0.89
.=</p>
<p>Experimental validation: results
.=</p>
<p>SAPS-QWH instance
 
.=</p>
<p>5
10 SPO+
.=</p>
<p>TB−SPO (w/ LHD)
.=</p>
<p>.
.=</p>
<p>4
10
.=</p>
<p> 
1 2 3
.=</p>
<p>10 10 10
CPU time t spent for configuration [s]
.=</p>
<p>Both methods with same LHD
.=</p>
<p>16
.=</p>
<p>performance p
t
.=</p>
<p>performance p
t.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Scenario SPO+ TB-SPO TB-Random pval1 pval2
.=</p>
<p>Saps-QCP-med [·10−2] 4.50± 0.31 4.32± 0.21 4.23 ± 0.15 4 · 10−3 0.17
Saps-QCP-q075 3.77± 9.72 0.19 ± 0.02 0.19 ± 0.01 2 · 10−6 0.78
Saps-QCP-q095 49.91± 0.00 2.20 ± 1.17 2.64± 1.24 1 · 10−10 0.12
Saps-QWH [·103] 10.7± 0.76 10.1± 0.58 9.88 ± 0.41 6 · 10−3 0.14
Saps-SWGCP-med 49.95± 0.00 0.18± 0.03 0.17 ± 0.02 1 · 10−10 0.37
Saps-SWGCP-q075 50± 0 0.24± 0.04 0.22 ± 0.03 1 · 10−10 0.08
Saps-SWGCP-q095 50± 0 0.25 ± 0.05 0.28± 0.10 1 · 10−10 0.89
.=</p>
<p>Experimental validation: results
.=</p>
<p>SAPS-QWH instance
  
.=</p>
<p>5 5
.=</p>
<p>10 SPO+ 10 SPO+
.=</p>
<p>TB−SPO (w/ LHD) TB−SPO (w/ LHD)
.=</p>
<p>. TB−SPO
.=</p>
<p>4 4
10 10
.=</p>
<p>  
1 2 3 1 2 3
.=</p>
<p>10 10 10 10 10 10
CPU time t spent for configuration [s] CPU time t spent for configuration [s]
.=</p>
<p>Both methods with same LHD TB-SPO with empty LHD
.=</p>
<p>16
.=</p>
<p>performance p
t
.=</p>
<p>performance p
t.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>TB-Random pval2
.=</p>
<p>4.23 ± 0.15 0.17
0.19 ± 0.01 0.78
2.64± 1.24 0.12
9.88 ± 0.41 0.14
0.17 ± 0.02 0.37
0.22 ± 0.03 0.08
0.28± 0.10 0.89
.=</p>
<p>Experimental validation: results
.=</p>
<p>SAPS-QWH instance
  
.=</p>
<p>5 5
.=</p>
<p>10 SPO+ 10 SPO+
.=</p>
<p>TB−SPO (w/ LHD) TB−SPO (w/ LHD)
.=</p>
<p>. TB−SPO
.=</p>
<p>4 4
10 10
.=</p>
<p>  
1 2 3 1 2 3
.=</p>
<p>10 10 10 10 10 10
CPU time t spent for configuration [s] CPU time t spent for configuration [s]
.=</p>
<p>Both methods with same LHD TB-SPO with empty LHD
.=</p>
<p>Scenario SPO+ TB-SPO pval1
.=</p>
<p>Saps-QCP-med [·10−2] 4.50± 0.31 4.32± 0.21 4 · 10−3
Saps-QCP-q075 3.77± 9.72 0.19 ± 0.02 2 · 10−6
Saps-QCP-q095 49.91± 0.00 2.20 ± 1.17 1 · 10−10
Saps-QWH [·103] 10.7± 0.76 10.1± 0.58 6 · 10−3
Saps-SWGCP-med 49.95± 0.00 0.18± 0.03 1 · 10−10
Saps-SWGCP-q075 50± 0 0.24± 0.04 1 · 10−10
Saps-SWGCP-q095 50± 0 0.25 ± 0.05 1 · 10−10
.=</p>
<p>16
.=</p>
<p>performance p
t
.=</p>
<p>performance p
t.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Experimental validation: results
.=</p>
<p>SAPS-QWH instance
  
.=</p>
<p>5 5
.=</p>
<p>10 SPO+ 10 SPO+
.=</p>
<p>TB−SPO (w/ LHD) TB−SPO (w/ LHD)
.=</p>
<p>. TB−SPO
.=</p>
<p>4 4
10 10
.=</p>
<p>  
1 2 3 1 2 3
.=</p>
<p>10 10 10 10 10 10
CPU time t spent for configuration [s] CPU time t spent for configuration [s]
.=</p>
<p>Both methods with same LHD TB-SPO with empty LHD
.=</p>
<p>Scenario SPO+ TB-SPO TB-Random pval1 pval2
.=</p>
<p>Saps-QCP-med [·10−2] 4.50± 0.31 4.32± 0.21 4.23 ± 0.15 4 · 10−3 0.17
Saps-QCP-q075 3.77± 9.72 0.19 ± 0.02 0.19 ± 0.01 2 · 10−6 0.78
Saps-QCP-q095 49.91± 0.00 2.20 ± 1.17 2.64± 1.24 1 · 10−10 0.12
Saps-QWH [·103] 10.7± 0.76 10.1± 0.58 9.88 ± 0.41 6 · 10−3 0.14
Saps-SWGCP-med 49.95± 0.00 0.18± 0.03 0.17 ± 0.02 1 · 10−10 0.37
Saps-SWGCP-q075 50± 0 0.24± 0.04 0.22 ± 0.03 1 · 10−10 0.08
Saps-SWGCP-q095 50± 0 0.25 ± 0.05 0.28± 0.10 1 · 10−10 0.89
.=</p>
<p>16
.=</p>
<p>performance p
t
.=</p>
<p>performance p
t.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Outline
.=</p>
<p>1. Sequential Model-Based Optimization
.=</p>
<p>2. Reducing the Computational Overhead Due To Models
Do More Algorithm Runs To Bound Model Overhead
Using a Cheaper (and Better!) Model
.=</p>
<p>3. Conclusions
.=</p>
<p>17.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>I Model II (used in SPO, SPO+, and TB-SPO)
– Compute empirical mean of responses at each param. setting
– Fit noise-free GP to those means
– But assumes empirical means are perfect (even when based on
.=</p>
<p>just 1 run!)
– Cheaper (here 11 means vs 110 raw data points)
.=</p>
<p>35  
.=</p>
<p>DACE mean prediction
.=</p>
<p>DACE mean +/− 2*stddev
30
.=</p>
<p>True function
.=</p>
<p>Function evaluations
.=</p>
<p>25 EI (scaled)
.=</p>
<p>20
.=</p>
<p>15
.=</p>
<p>10
.=</p>
<p>5
.=</p>
<p>0
.=</p>
<p>−5  
0 0.2 0.4 0.6 0.8 1
.=</p>
<p>parameter x
.=</p>
<p>Model II: noise-free fit of empir. means
.=</p>
<p>2 Different GP Models for Noisy Optimization
.=</p>
<p>I Model I
– Fit standard GP assuming Gaussian observation noise
.=</p>
<p>35  
.=</p>
<p>GP mean prediction
.=</p>
<p>GP mean +/− 2*stddev
30
.=</p>
<p>True function
.=</p>
<p>Function evaluations
.=</p>
<p>25 EI (scaled)
.=</p>
<p>20
.=</p>
<p>15
.=</p>
<p>10
.=</p>
<p>5
.=</p>
<p>0
.=</p>
<p>−5  
0 0.2 0.4 0.6 0.8 1
.=</p>
<p>parameter x
.=</p>
<p>Model I: noisy fit of original response
18
.=</p>
<p>response y
.=</p>
<p>response y.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>– But assumes empirical means are perfect (even when based on
just 1 run!)
.=</p>
<p>– Cheaper (here 11 means vs 110 raw data points)
.=</p>
<p>2 Different GP Models for Noisy Optimization
.=</p>
<p>I Model I
– Fit standard GP assuming Gaussian observation noise
.=</p>
<p>I Model II (used in SPO, SPO+, and TB-SPO)
– Compute empirical mean of responses at each param. setting
– Fit noise-free GP to those means
.=</p>
<p>35  35  
.=</p>
<p>GP mean prediction DACE mean prediction
.=</p>
<p>GP mean +/− 2*stddev DACE mean +/− 2*stddev
30 30
.=</p>
<p>True function True function
.=</p>
<p>Function evaluations Function evaluations
.=</p>
<p>25 EI (scaled) 25 EI (scaled)
.=</p>
<p>20 20
.=</p>
<p>15 15
.=</p>
<p>10 10
.=</p>
<p>5 5
.=</p>
<p>0 0
.=</p>
<p>−5  −5  
0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1
.=</p>
<p>parameter x parameter x
.=</p>
<p>Model I: noisy fit of original response Model II: noise-free fit of empir. means
18
.=</p>
<p>response y
.=</p>
<p>response y.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>– Cheaper (here 11 means vs 110 raw data points)
.=</p>
<p>2 Different GP Models for Noisy Optimization
.=</p>
<p>I Model I
– Fit standard GP assuming Gaussian observation noise
.=</p>
<p>I Model II (used in SPO, SPO+, and TB-SPO)
– Compute empirical mean of responses at each param. setting
– Fit noise-free GP to those means
– But assumes empirical means are perfect (even when based on
.=</p>
<p>just 1 run!)
.=</p>
<p>35  35  
.=</p>
<p>GP mean prediction DACE mean prediction
.=</p>
<p>GP mean +/− 2*stddev DACE mean +/− 2*stddev
30 30
.=</p>
<p>True function True function
.=</p>
<p>Function evaluations Function evaluations
.=</p>
<p>25 EI (scaled) 25 EI (scaled)
.=</p>
<p>20 20
.=</p>
<p>15 15
.=</p>
<p>10 10
.=</p>
<p>5 5
.=</p>
<p>0 0
.=</p>
<p>−5  −5  
0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1
.=</p>
<p>parameter x parameter x
.=</p>
<p>Model I: noisy fit of original response Model II: noise-free fit of empir. means
18
.=</p>
<p>response y
.=</p>
<p>response y.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>2 Different GP Models for Noisy Optimization
.=</p>
<p>I Model I
– Fit standard GP assuming Gaussian observation noise
.=</p>
<p>I Model II (used in SPO, SPO+, and TB-SPO)
– Compute empirical mean of responses at each param. setting
– Fit noise-free GP to those means
– But assumes empirical means are perfect (even when based on
.=</p>
<p>just 1 run!)
– Cheaper (here 11 means vs 110 raw data points)
.=</p>
<p>35  35  
.=</p>
<p>GP mean prediction DACE mean prediction
.=</p>
<p>GP mean +/− 2*stddev DACE mean +/− 2*stddev
30 30
.=</p>
<p>True function True function
.=</p>
<p>Function evaluations Function evaluations
.=</p>
<p>25 EI (scaled) 25 EI (scaled)
.=</p>
<p>20 20
.=</p>
<p>15 15
.=</p>
<p>10 10
.=</p>
<p>5 5
.=</p>
<p>0 0
.=</p>
<p>−5  −5  
0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1
.=</p>
<p>parameter x parameter x
.=</p>
<p>Model I: noisy fit of original response Model II: noise-free fit of empir. means
18
.=</p>
<p>response y
.=</p>
<p>response y.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p> O(h · n3) for model fitting
I O(n2) for each model prediction
.=</p>
<p>Complexity of projected process (PP) approximation
.=</p>
<p>I Active set of p data points  only invert p × p matrix
I Throughout: use p = 300
.=</p>
<p>I O(n · p2 + h · p3) for model fitting
I O(p2) for each model prediction
.=</p>
<p>How much faster is the approximate Gaussian
Process?
.=</p>
<p>Complexity of Gaussian process regression (GPR)
.=</p>
<p>I n data points
.=</p>
<p>I Basic GPR equations: inverting n × n matrix
I Numerical optimization of hyper-parameters: h steps
.=</p>
<p>19.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>I O(n2) for each model prediction
.=</p>
<p>Complexity of projected process (PP) approximation
.=</p>
<p>I Active set of p data points  only invert p × p matrix
I Throughout: use p = 300
.=</p>
<p>I O(n · p2 + h · p3) for model fitting
I O(p2) for each model prediction
.=</p>
<p>How much faster is the approximate Gaussian
Process?
.=</p>
<p>Complexity of Gaussian process regression (GPR)
.=</p>
<p>I n data points
.=</p>
<p>I Basic GPR equations: inverting n × n matrix
I Numerical optimization of hyper-parameters: h steps
.=</p>
<p> O(h · n3) for model fitting
.=</p>
<p>19.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Complexity of projected process (PP) approximation
.=</p>
<p>I Active set of p data points  only invert p × p matrix
I Throughout: use p = 300
.=</p>
<p>I O(n · p2 + h · p3) for model fitting
I O(p2) for each model prediction
.=</p>
<p>How much faster is the approximate Gaussian
Process?
.=</p>
<p>Complexity of Gaussian process regression (GPR)
.=</p>
<p>I n data points
.=</p>
<p>I Basic GPR equations: inverting n × n matrix
I Numerical optimization of hyper-parameters: h steps
.=</p>
<p> O(h · n3) for model fitting
I O(n2) for each model prediction
.=</p>
<p>19.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>I O(n · p2 + h · p3) for model fitting
I O(p2) for each model prediction
.=</p>
<p>How much faster is the approximate Gaussian
Process?
.=</p>
<p>Complexity of Gaussian process regression (GPR)
.=</p>
<p>I n data points
.=</p>
<p>I Basic GPR equations: inverting n × n matrix
I Numerical optimization of hyper-parameters: h steps
.=</p>
<p> O(h · n3) for model fitting
I O(n2) for each model prediction
.=</p>
<p>Complexity of projected process (PP) approximation
.=</p>
<p>I Active set of p data points  only invert p × p matrix
I Throughout: use p = 300
.=</p>
<p>19.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>How much faster is the approximate Gaussian
Process?
.=</p>
<p>Complexity of Gaussian process regression (GPR)
.=</p>
<p>I n data points
.=</p>
<p>I Basic GPR equations: inverting n × n matrix
I Numerical optimization of hyper-parameters: h steps
.=</p>
<p> O(h · n3) for model fitting
I O(n2) for each model prediction
.=</p>
<p>Complexity of projected process (PP) approximation
.=</p>
<p>I Active set of p data points  only invert p × p matrix
I Throughout: use p = 300
.=</p>
<p>I O(n · p2 + h · p3) for model fitting
I O(p2) for each model prediction
.=</p>
<p>19.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Empirical model quality
.=</p>
<p>I Measures correlation between
.=</p>
<p>– how promising the model judges a parameter setting to be
– true performance of that parameter setting (evaluated offline)
.=</p>
<p>0.8
0.6 0.8 0.60.8
.=</p>
<p>0.8 0.6
.=</p>
<p>0.5 0.6 0.4
0.4
.=</p>
<p>0.7
0.4 0.7 0.6 0.4 0.2 0.2
.=</p>
<p>0.3 0.6 0.6 0.2 0 0
0.4
.=</p>
<p>0.2 −0.2
0.5
.=</p>
<p>0.5 0 −0.2
.=</p>
<p>PP NF PP NF PP NF PP NF PP NF PP NF PP NF
QCP−med QCP−q075 QCP−q095 QWH SWGCP−med SWGCP−q075 SWGCP−q095
.=</p>
<p>Correlation (high is good, 1 is optimal)
.=</p>
<p>Empirical Evaluation of the Model
.=</p>
<p>Empirical time performance (1 000 data points)
.=</p>
<p>2 2 2 2 2 2 2
.=</p>
<p>1.5 1.5 1.5 1.5 1.5 1.5 1.5
.=</p>
<p>1 1 1 1 1 1 1
.=</p>
<p>0.5 0.5 0.5 0.5 0.5 0.5 0.5
.=</p>
<p>PP NF PP NF PP NF PP NF PP NF PP NF PP NF
QCP−med QCP−q075 QCP−q095 QWH SWGCP−med SWGCP−q075 SWGCP−q095
.=</p>
<p>Log10 of CPU time (in seconds)
.=</p>
<p>20.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>0.8
0.6 0.8 0.60.8
.=</p>
<p>0.8 0.6
.=</p>
<p>0.5 0.6 0.4
0.4
.=</p>
<p>0.7
0.4 0.7 0.6 0.4 0.2 0.2
.=</p>
<p>0.3 0.6 0.6 0.2 0 0
0.4
.=</p>
<p>0.2 −0.2
0.5
.=</p>
<p>0.5 0 −0.2
.=</p>
<p>PP NF PP NF PP NF PP NF PP NF PP NF PP NF
QCP−med QCP−q075 QCP−q095 QWH SWGCP−med SWGCP−q075 SWGCP−q095
.=</p>
<p>Correlation (high is good, 1 is optimal)
.=</p>
<p>Empirical Evaluation of the Model
.=</p>
<p>Empirical time performance (1 000 data points)
.=</p>
<p>2 2 2 2 2 2 2
.=</p>
<p>1.5 1.5 1.5 1.5 1.5 1.5 1.5
.=</p>
<p>1 1 1 1 1 1 1
.=</p>
<p>0.5 0.5 0.5 0.5 0.5 0.5 0.5
.=</p>
<p>PP NF PP NF PP NF PP NF PP NF PP NF PP NF
QCP−med QCP−q075 QCP−q095 QWH SWGCP−med SWGCP−q075 SWGCP−q095
.=</p>
<p>Log10 of CPU time (in seconds)
.=</p>
<p>Empirical model quality
.=</p>
<p>I Measures correlation between
.=</p>
<p>– how promising the model judges a parameter setting to be
– true performance of that parameter setting (evaluated offline)
.=</p>
<p>20.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Empirical Evaluation of the Model
.=</p>
<p>Empirical time performance (1 000 data points)
.=</p>
<p>2 2 2 2 2 2 2
.=</p>
<p>1.5 1.5 1.5 1.5 1.5 1.5 1.5
.=</p>
<p>1 1 1 1 1 1 1
.=</p>
<p>0.5 0.5 0.5 0.5 0.5 0.5 0.5
.=</p>
<p>PP NF PP NF PP NF PP NF PP NF PP NF PP NF
QCP−med QCP−q075 QCP−q095 QWH SWGCP−med SWGCP−q075 SWGCP−q095
.=</p>
<p>Log10 of CPU time (in seconds)
.=</p>
<p>Empirical model quality
.=</p>
<p>I Measures correlation between
.=</p>
<p>– how promising the model judges a parameter setting to be
– true performance of that parameter setting (evaluated offline)
.=</p>
<p>0.8
0.6 0.8 0.60.8
.=</p>
<p>0.8 0.6
.=</p>
<p>0.5 0.6 0.4
0.4
.=</p>
<p>0.7
0.4 0.7 0.6 0.4 0.2 0.2
.=</p>
<p>0.3 0.6 0.6 0.2 0 0
0.4
.=</p>
<p>0.2 −0.2
0.5
.=</p>
<p>0.5 0 −0.2
.=</p>
<p>PP NF PP NF PP NF PP NF PP NF PP NF PP NF
QCP−med QCP−q075 QCP−q095 QWH SWGCP−med SWGCP−q075 SWGCP−q095
.=</p>
<p>Correlation (high is good, 1 is optimal)
20.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>I P: TB-SPO(PP)
I F: FocusedILS (variant of ParamILS; limited by discretization)
.=</p>
<p>Scenario TB-Random TB-SPO TB-SPO(PP) FocusedILS
−2
.=</p>
<p>Saps-QCP-med [·10 ] 4.23 ± 0.15 4.32 ± 0.21 4.13 ± 0.14 5.12 ± 0.41
Saps-QCP-q075 0.19 ± 0.01 0.19 ± 0.02 0.18 ± 0.01 0.24 ± 0.02
Saps-QCP-q095 2.64 ± 1.24 2.20 ± 1.17 1.44 ± 0.53 2.99 ± 3.20
.=</p>
<p>3
Saps-QWH [·10 ] 9.88 ± 0.41 10.1 ± 0.58 9.42 ± 0.32 10.6 ± 0.49
Saps-SWGCP-med 0.17 ± 0.02 0.18 ± 0.03 0.16 ± 0.02 0.27 ± 0.12
Saps-SWGCP-q075 0.22 ± 0.03 0.24 ± 0.04 0.21 ± 0.02 0.35 ± 0.08
Saps-SWGCP-q095 0.28 ± 0.10 0.25 ± 0.05 0.23 ± 0.05 0.37 ± 0.16
.=</p>
<p>I TB-SPO(PP) best on all 7 instances
I Good models do help
.=</p>
<p>Final Evaluation
.=</p>
<p>I Comparing:
I R: TB-Random
I S: TB-SPO
.=</p>
<p>21.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>I F: FocusedILS (variant of ParamILS; limited by discretization)
.=</p>
<p>Scenario TB-Random TB-SPO TB-SPO(PP) FocusedILS
−2
.=</p>
<p>Saps-QCP-med [·10 ] 4.23 ± 0.15 4.32 ± 0.21 4.13 ± 0.14 5.12 ± 0.41
Saps-QCP-q075 0.19 ± 0.01 0.19 ± 0.02 0.18 ± 0.01 0.24 ± 0.02
Saps-QCP-q095 2.64 ± 1.24 2.20 ± 1.17 1.44 ± 0.53 2.99 ± 3.20
Saps-QWH [·103] 9.88 ± 0.41 10.1 ± 0.58 9.42 ± 0.32 10.6 ± 0.49
Saps-SWGCP-med 0.17 ± 0.02 0.18 ± 0.03 0.16 ± 0.02 0.27 ± 0.12
Saps-SWGCP-q075 0.22 ± 0.03 0.24 ± 0.04 0.21 ± 0.02 0.35 ± 0.08
Saps-SWGCP-q095 0.28 ± 0.10 0.25 ± 0.05 0.23 ± 0.05 0.37 ± 0.16
.=</p>
<p>I TB-SPO(PP) best on all 7 instances
I Good models do help
.=</p>
<p>Final Evaluation
.=</p>
<p>I Comparing:
I R: TB-Random
I S: TB-SPO
I P: TB-SPO(PP)
.=</p>
<p>21.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Scenario TB-Random TB-SPO TB-SPO(PP) FocusedILS
−2
.=</p>
<p>Saps-QCP-med [·10 ] 4.23 ± 0.15 4.32 ± 0.21 4.13 ± 0.14 5.12 ± 0.41
Saps-QCP-q075 0.19 ± 0.01 0.19 ± 0.02 0.18 ± 0.01 0.24 ± 0.02
Saps-QCP-q095 2.64 ± 1.24 2.20 ± 1.17 1.44 ± 0.53 2.99 ± 3.20
Saps-QWH [·103] 9.88 ± 0.41 10.1 ± 0.58 9.42 ± 0.32 10.6 ± 0.49
Saps-SWGCP-med 0.17 ± 0.02 0.18 ± 0.03 0.16 ± 0.02 0.27 ± 0.12
Saps-SWGCP-q075 0.22 ± 0.03 0.24 ± 0.04 0.21 ± 0.02 0.35 ± 0.08
Saps-SWGCP-q095 0.28 ± 0.10 0.25 ± 0.05 0.23 ± 0.05 0.37 ± 0.16
.=</p>
<p>I TB-SPO(PP) best on all 7 instances
I Good models do help
.=</p>
<p>Final Evaluation
.=</p>
<p>I Comparing:
I R: TB-Random
I S: TB-SPO
I P: TB-SPO(PP)
I F: FocusedILS (variant of ParamILS; limited by discretization)
.=</p>
<p>21.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Final Evaluation
.=</p>
<p>I Comparing:
I R: TB-Random
I S: TB-SPO
I P: TB-SPO(PP)
I F: FocusedILS (variant of ParamILS; limited by discretization)
.=</p>
<p>Scenario TB-Random TB-SPO TB-SPO(PP) FocusedILS
.=</p>
<p>[·10−2Saps-QCP-med ] 4.23 ± 0.15 4.32 ± 0.21 4.13 ± 0.14 5.12 ± 0.41
Saps-QCP-q075 0.19 ± 0.01 0.19 ± 0.02 0.18 ± 0.01 0.24 ± 0.02
Saps-QCP-q095 2.64 ± 1.24 2.20 ± 1.17 1.44 ± 0.53 2.99 ± 3.20
.=</p>
<p>3
Saps-QWH [·10 ] 9.88 ± 0.41 10.1 ± 0.58 9.42 ± 0.32 10.6 ± 0.49
Saps-SWGCP-med 0.17 ± 0.02 0.18 ± 0.03 0.16 ± 0.02 0.27 ± 0.12
Saps-SWGCP-q075 0.22 ± 0.03 0.24 ± 0.04 0.21 ± 0.02 0.35 ± 0.08
Saps-SWGCP-q095 0.28 ± 0.10 0.25 ± 0.05 0.23 ± 0.05 0.37 ± 0.16
.=</p>
<p>I TB-SPO(PP) best on all 7 instances
I Good models do help
.=</p>
<p>21.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Outline
.=</p>
<p>1. Sequential Model-Based Optimization
.=</p>
<p>2. Reducing the Computational Overhead Due To Models
.=</p>
<p>3. Conclusions
.=</p>
<p>22.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Sequential Parameter Optimization (SPO)
.=</p>
<p>I Uses predictive models of algorithm performance
.=</p>
<p>I Can inform algorithm designer about parameter space
.=</p>
<p>Time-Bounded SPO
I Eliminates Computational Overheads of SPO
.=</p>
<p>– No need for costly initial design
– Bounds the time spent building and using the model
– Uses efficient approximate Gaussian process model
 Practical for parameter optimization in a time budget
.=</p>
<p>I Clearly outperforms previous SPO versions and ParamILS
.=</p>
<p>Conclusions
.=</p>
<p>Parameter optimization
I Can be performed by automated approaches
.=</p>
<p>– Sometimes much better than by human experts
– Automation can cut development time & improve results
.=</p>
<p>23.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Time-Bounded SPO
I Eliminates Computational Overheads of SPO
.=</p>
<p>– No need for costly initial design
– Bounds the time spent building and using the model
– Uses efficient approximate Gaussian process model
 Practical for parameter optimization in a time budget
.=</p>
<p>I Clearly outperforms previous SPO versions and ParamILS
.=</p>
<p>Conclusions
.=</p>
<p>Parameter optimization
I Can be performed by automated approaches
.=</p>
<p>– Sometimes much better than by human experts
– Automation can cut development time & improve results
.=</p>
<p>Sequential Parameter Optimization (SPO)
.=</p>
<p>I Uses predictive models of algorithm performance
.=</p>
<p>I Can inform algorithm designer about parameter space
.=</p>
<p>23.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>I Clearly outperforms previous SPO versions and ParamILS
.=</p>
<p>Conclusions
.=</p>
<p>Parameter optimization
I Can be performed by automated approaches
.=</p>
<p>– Sometimes much better than by human experts
– Automation can cut development time & improve results
.=</p>
<p>Sequential Parameter Optimization (SPO)
.=</p>
<p>I Uses predictive models of algorithm performance
.=</p>
<p>I Can inform algorithm designer about parameter space
.=</p>
<p>Time-Bounded SPO
I Eliminates Computational Overheads of SPO
.=</p>
<p>– No need for costly initial design
– Bounds the time spent building and using the model
– Uses efficient approximate Gaussian process model
 Practical for parameter optimization in a time budget
.=</p>
<p>23.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Conclusions
.=</p>
<p>Parameter optimization
I Can be performed by automated approaches
.=</p>
<p>– Sometimes much better than by human experts
– Automation can cut development time & improve results
.=</p>
<p>Sequential Parameter Optimization (SPO)
.=</p>
<p>I Uses predictive models of algorithm performance
.=</p>
<p>I Can inform algorithm designer about parameter space
.=</p>
<p>Time-Bounded SPO
I Eliminates Computational Overheads of SPO
.=</p>
<p>– No need for costly initial design
– Bounds the time spent building and using the model
– Uses efficient approximate Gaussian process model
 Practical for parameter optimization in a time budget
.=</p>
<p>I Clearly outperforms previous SPO versions and ParamILS
23.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>I Applications of Automated Parameter Optimization
.=</p>
<p>– Optimization of MIP solvers [to be submitted to CP-AI-OR]
.=</p>
<p>I Use models to gain scientific insights
.=</p>
<p>– Importance of each parameter
– Interaction of parameters
– Interaction of parameters and instances features
.=</p>
<p>I Per-instance approaches
.=</p>
<p>– Build joint model of instance features and parameters
– Given a new unseen instance:
.=</p>
<p>+ Compute instance features (fast)
+ Use parameter setting predicted to be best for those features
.=</p>
<p>Current & Future Work
.=</p>
<p>I Generalizations of TB-SPO to handle
.=</p>
<p>– Categorical parameters
– Multiple benchmark instances
.=</p>
<p>24.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>I Use models to gain scientific insights
.=</p>
<p>– Importance of each parameter
– Interaction of parameters
– Interaction of parameters and instances features
.=</p>
<p>I Per-instance approaches
.=</p>
<p>– Build joint model of instance features and parameters
– Given a new unseen instance:
.=</p>
<p>+ Compute instance features (fast)
+ Use parameter setting predicted to be best for those features
.=</p>
<p>Current & Future Work
.=</p>
<p>I Generalizations of TB-SPO to handle
.=</p>
<p>– Categorical parameters
– Multiple benchmark instances
.=</p>
<p>I Applications of Automated Parameter Optimization
.=</p>
<p>– Optimization of MIP solvers [to be submitted to CP-AI-OR]
.=</p>
<p>24.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>I Per-instance approaches
.=</p>
<p>– Build joint model of instance features and parameters
– Given a new unseen instance:
.=</p>
<p>+ Compute instance features (fast)
+ Use parameter setting predicted to be best for those features
.=</p>
<p>Current & Future Work
.=</p>
<p>I Generalizations of TB-SPO to handle
.=</p>
<p>– Categorical parameters
– Multiple benchmark instances
.=</p>
<p>I Applications of Automated Parameter Optimization
.=</p>
<p>– Optimization of MIP solvers [to be submitted to CP-AI-OR]
.=</p>
<p>I Use models to gain scientific insights
.=</p>
<p>– Importance of each parameter
– Interaction of parameters
– Interaction of parameters and instances features
.=</p>
<p>24.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Current & Future Work
.=</p>
<p>I Generalizations of TB-SPO to handle
.=</p>
<p>– Categorical parameters
– Multiple benchmark instances
.=</p>
<p>I Applications of Automated Parameter Optimization
.=</p>
<p>– Optimization of MIP solvers [to be submitted to CP-AI-OR]
.=</p>
<p>I Use models to gain scientific insights
.=</p>
<p>– Importance of each parameter
– Interaction of parameters
– Interaction of parameters and instances features
.=</p>
<p>I Per-instance approaches
.=</p>
<p>– Build joint model of instance features and parameters
– Given a new unseen instance:
.=</p>
<p>+ Compute instance features (fast)
+ Use parameter setting predicted to be best for those features
.=</p>
<p>24.=</p>
</div>
</body>
		<back>
			<div type="references">

				<listBibl>


				</listBibl>
			</div>
		</back>
	</text>
</TEI>
