<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /mnt/sda1/Dissertation/grobid/grobid-0.5.6/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Multi-agent reinforcement learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2019-12-22">December 22, 2019</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Schnebli</forename><surname>Zoltan</surname></persName>
						</author>
						<title level="a" type="main">Multi-agent reinforcement learning</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2019-12-22">December 22, 2019</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.5.6" ident="GROBID" when="2019-12-24T15:31+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Learning the Empirical Hardness 
of Combinatorial Auctions
.=</p>
<p>Kevin Leyton-Brown
Eugene Nudelman
Yoav Shoham
.=</p>
<p>Computer Science
Stanford University
.=</p>
<p>Thanks to: 
Carla Gomes, Bart Selman, Rámon Béjar
Ioannis Vetsikas, and Henry Kautz.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Introduction
.=</p>
<p>Recent trend: study of average/empirical 
hardness as opposed to the worst-case 
complexity (NP-Hardness) [Cheeseman et al.; 
Selman et al.]
.=</p>
<p>Our proposal: predict the running time of 
an algorithm on a particular instance based 
on features of that instance
Today: 
.=</p>
<p>a methodology for doing this 
its application to the combinatorial auction 
winner determination problem (WDP)
.=</p>
<p>September 12, 2004 Constraint Programming 2002, Cornell 2.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Why?
.=</p>
<p>Predict running time
for its own sake
build algorithm portfolios
.=</p>
<p>Theoretical understanding of hardness
tune distributions for hardness
improve algorithms
.=</p>
<p>Problem specific
WDP: design bidding rules
.=</p>
<p>September 12, 2004 Constraint Programming 2002, Cornell 3.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Related Work
Decision problems:
.=</p>
<p>phase transitions in solvability, corresponding to 
hardness spike [Cheeseman et al.; Selman et al.]
solution invariants: e.g., backbone [Gomes et al.]
.=</p>
<p>Optimization problems:
experimental: 
.=</p>
<p>• reduce to decision problem    [Zhang et al.]
• introduce backbone concepts [Walsh et al.]
.=</p>
<p>theoretical: 
• polynomial/exponential transition in search algorithms 
.=</p>
<p>[Zhang]
• predict A* nodes expanded for problem distribution [Korf, 
.=</p>
<p>Reid]
.=</p>
<p>Learning
dynamic restart policies [Kautz et al.]
.=</p>
<p>September 12, 2004 Constraint Programming 2002, Cornell 4.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Combinatorial Auctions
.=</p>
<p>Auctioneer sells a set of non-homogeneous items
Bidders often have complex valuations
.=</p>
<p>complementarities
• e.g. V(TV & VCR) > V(TV) + V(VCR)
.=</p>
<p>substitutabilities
• V(TV1 & TV2) < V(TV1) + V(TV2)
.=</p>
<p>Solution: allow bids on bundles of goods
achieves a higher revenue and social welfare than 
separate auctions
.=</p>
<p>Two hard problems:
Expressing valuations
Determining optimal allocation
.=</p>
<p>September 12, 2004 Constraint Programming 2002, Cornell 5.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Winner Determination Problem
.=</p>
<p>Equivalent to weighted set packing
Input: m bids
Objective: find revenue-maximizing non-
conflicting allocation
.=</p>
<p>Even constant factor approximation is NP-Hard
Square-root approximation known
Polynomial in the number of bids
.=</p>
<p>September 12, 2004 Constraint Programming 2002, Cornell 6.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>WDP Case Study
.=</p>
<p>Difficulty: highly parameterized, complex 
distributions
Hard to analyze theoretically
.=</p>
<p>large variation in edge costs and branching 
factors throughout the search tree [Korf, Reid, Zhang]
.=</p>
<p>Too many parameters to vary 
systematically [Walsh et al., Gomes et. al.]
Parameters affect expected optimum: 
difficult to transform to decision problem 
[Zhang et al.]
.=</p>
<p>September 12, 2004 Constraint Programming 2002, Cornell 7.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Methodology
.=</p>
<p>1. Select algorithm
2. Select set of input distributions
3. Factor out known sources of hardness
4. Choose features
5. Generate instances
6. Compute running time, features
7. Learn a model of running time
.=</p>
<p>September 12, 2004 Constraint Programming 2002, Cornell 8.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Methodology
.=</p>
<p>1. Select algorithm: ILOG’s CPLEX 7.1
2. Select set of input distributions
3. Factor out known sources of hardness
4. Choose features
5. Generate instances
6. Compute running time, features
7. Learn a model of running time
.=</p>
<p>September 12, 2004 Constraint Programming 2002, Cornell 9.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Methodology
.=</p>
<p>1. Select algorithm
2. Select set of input distributions
3. Factor out known sources of hardness
4. Choose features
5. Generate instances
6. Compute running time, features
7. Learn a model of running time
.=</p>
<p>September 12, 2004 Constraint Programming 2002, Cornell 10.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>WDP Distributions
.=</p>
<p>Legacy (7 distributions)
sample bid sizes/prices independently from 
simple statistical distributions
.=</p>
<p>Combinatorial Auctions Test Suite (CATS)
Attempted to model bidder valuations to 
provide more motivated CA distributions
.=</p>
<p>1. regions: real estate
2. arbitrary: complementarity described by 
.=</p>
<p>weighted graph
3. matching: FAA take-off & landing auctions
4. scheduling: single resource, multiple deadlines 
.=</p>
<p>for each agent [Wellman]
.=</p>
<p>September 12, 2004 Constraint Programming 2002, Cornell 11.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Methodology
.=</p>
<p>1. Select algorithm
2. Select set of input distributions
3. Factor out known sources of hardness
4. Choose features
5. Generate instances
6. Compute running time, features
7. Learn a model of running time
.=</p>
<p>September 12, 2004 Constraint Programming 2002, Cornell 12.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Problem Size
.=</p>
<p>Some sources of hardness well-understood
hold these constant to focus on unknown 
sources of hardness
.=</p>
<p>Common: input size
Problem size is affected by preprocessing 
techniques! (e.g. arc-consistency)
WDP: dominated bids can be removed
(raw #bids, #goods) is a very misleading
measure of size for legacy distributions
.=</p>
<p>we fix size as (#non-dominated bids, #goods) 
.=</p>
<p>September 12, 2004 Constraint Programming 2002, Cornell 13.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Raw vs. Non-Dominated Bids
(64 goods, target of 2000 non-dominated bids)
.=</p>
<p>2000
L7: Binomial L6: Exponential
.=</p>
<p>1800 L3: Uniform L2: Weighted Random
.=</p>
<p>1600 L5: Normal
.=</p>
<p>1400
.=</p>
<p>1200
L4: Decay
.=</p>
<p>1000
.=</p>
<p>800
.=</p>
<p>600
.=</p>
<p>400
L1: Uniform Random
.=</p>
<p>200
.=</p>
<p>0
0 2000 4000 6000 8000
.=</p>
<p>Raw Number of Bids L1 L2 L3 L4 L5 L6 L7
September 12, 2004 Constraint Programming 2002, Cornell 14
.=</p>
<p>Number of Non-Dominated Bids
(average over 20 runs).=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Methodology
.=</p>
<p>1. Select algorithm
2. Select set of input distributions
3. Factor out known sources of hardness
4. Choose features
5. Generate instances
6. Compute running time, features
7. Learn a model of running time
.=</p>
<p>September 12, 2004 Constraint Programming 2002, Cornell 15.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Features
.=</p>
<p>No automatic way to construct features
must come from domain knowledge
.=</p>
<p>We require features to be:
polynomial-time computable
distribution-independent
.=</p>
<p>We identified 35 features
after using various statistical feature selection 
techniques, we were left with 25
.=</p>
<p>September 12, 2004 Constraint Programming 2002, Cornell 16.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Features
.=</p>
<p>Bid Good Graph Bid Graph (BG)
(BGG) 3. node degree stats
1. Bid node degree stats 4. edge density
2. Good node degree stats 5. clustering coef. and 
.=</p>
<p>deviation
6. avg. min. path. length
7. ratio of 5 & 6
8. node eccentricity stats
.=</p>
<p>Price-based features
9. std. deviation LP Relaxation 
10. stdev price/#goods
.=</p>
<p>12. L , L , L norms of 
11. stdev price/ √#goods 1 2 ∞integer slack vector
.=</p>
<p>September 12, 2004 Constraint Programming 2002, Cornell 17.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Methodology
.=</p>
<p>1. Select algorithm
2. Select set of input distributions
3. Factor out known sources of hardness
4. Choose features
5. Generate instances
6. Compute running time, features
7. Learn a model of running time
.=</p>
<p>September 12, 2004 Constraint Programming 2002, Cornell 18.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Experimental Setup
.=</p>
<p>Sample parameters uniformly from range of 
acceptable values
3 separate datasets:
.=</p>
<p>256 goods, 1000 non-dominated bids
144 goods, 1000 non-dominated bids
64 goods, 2000 non-dominated bids
.=</p>
<p>4500 instances/dataset, from 9 distributions
Collecting data took approximately 3 years of 
CPU time! (550 MHz Xeons, Linux 2.12)
Running times varied from 0.01 sec to 22 hours 
(CPLEX capped at 130000 nodes)
.=</p>
<p>September 12, 2004 Constraint Programming 2002, Cornell 19.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Gross Hardness (256 goods, 1000 bids)
.=</p>
<p>100%
.=</p>
<p>90%
.=</p>
<p>80%
.=</p>
<p>70%
.=</p>
<p>60%
.=</p>
<p>50%
.=</p>
<p>40%
.=</p>
<p>30%
.=</p>
<p>20%
.=</p>
<p>10%
.=</p>
<p>0%
L
.=</p>
<p>L 37
-1 A
.=</p>
<p>L rb0 4 itr
1 R
.=</p>
<p>a
e ryL g
.=</p>
<p>2 2 ioL ns
Running Time 3 6Sch Distributionlog10(sec) 4 Pa e
.=</p>
<p>5 M t
d
.=</p>
<p>h u
500 instances 
.=</p>
<p>a s
lin
.=</p>
<p>tc g
in each
.=</p>
<p>hing
.=</p>
<p>September 12, 2004 Constraint Programming 2002, Cornell 20.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Methodology
.=</p>
<p>1. Select algorithm
2. Select set of input distributions
3. Factor out known sources of hardness
4. Choose features
5. Generate instances
6. Compute running time, features
7. Learn a model of running time
.=</p>
<p>September 12, 2004 Constraint Programming 2002, Cornell 21.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Learning
.=</p>
<p>Classification: misleading error measure
Statistical regression: learn a continuous function 
of features that predicts log of running time
Supervised learning: data broken into 80% 
training set, 20% test set
Started with simplest technique: linear regression
.=</p>
<p>find a hyperplane that minimizes root mean squared 
error (RMSE) on training data
.=</p>
<p>Linear regression is useful:
as a (surprisingly good) baseline
yields a very interpretable model with understandable 
variables
.=</p>
<p>September 12, 2004 Constraint Programming 2002, Cornell 22.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>LR: Error
.=</p>
<p>Dataset RMSE MAE
.=</p>
<p>1000 Bids, 256 Goods 0.581 0.436
.=</p>
<p>160
.=</p>
<p>140
.=</p>
<p>120
.=</p>
<p>100
.=</p>
<p>80 1
60
.=</p>
<p>40
.=</p>
<p>20
.=</p>
<p>0
0.1 0.3 0.5 0.7 0.9 1.1 1.3 1.5 1.7 1.9 2.1 2.3 2.5 2.7
.=</p>
<p>Absolute Error
.=</p>
<p>September 12, 2004 Constraint Programming 2002, Cornell 23
.=</p>
<p>Count.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>LR: Subset Selection
.=</p>
<p>2
.=</p>
<p>1.8
.=</p>
<p>1.6
.=</p>
<p>1.4
.=</p>
<p>1.2
.=</p>
<p>1
.=</p>
<p>0.8
.=</p>
<p>0.6
.=</p>
<p>0.4 7
0.2
.=</p>
<p>0
0 5 10 15 20 25
.=</p>
<p>Subset Size
September 12, 2004 Constraint Programming 2002, Cornell 24
.=</p>
<p>RMSE.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>LR: Cost of Omission (subset size 7)
.=</p>
<p>BG: Edge Density
.=</p>
<p>BG: Clustering Coefficient
.=</p>
<p>BGG: Avg Good Degree
.=</p>
<p>BGG: Min Good Degree
.=</p>
<p>LP: L1 Norm
.=</p>
<p>BG: Degree Deviation
.=</p>
<p>BGG: Min Bid Degree
.=</p>
<p>0 10 20 30 40 50 60 70 80 90 100
.=</p>
<p>Cost of Omission
.=</p>
<p>September 12, 2004 Constraint Programming 2002, Cornell 25.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Non-Linear Approaches
.=</p>
<p>Linear regression doesn’t consider interactions 
between variables; likely to underfit data
Consider 2nd degree polynomials
Variables = pairwise products of original features
.=</p>
<p>total of 325 variables
(cf. clauses/variables)
.=</p>
<p>More predictability, less interpretability
.=</p>
<p>September 12, 2004 Constraint Programming 2002, Cornell 26.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Quadratic vs Linear Regression
.=</p>
<p>0.45
0.436 Linear
.=</p>
<p>0.4 Quadratic
0.35
.=</p>
<p>0.3
.=</p>
<p>0.25
.=</p>
<p>0.2 0.216
.=</p>
<p>0.15
.=</p>
<p>0.1
.=</p>
<p>0.05
.=</p>
<p>0
1000 Bids 256 Goods
.=</p>
<p>September 12, 2004 Constraint Programming 2002, Cornell 27.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Quadratic vs Linear Regression
350
.=</p>
<p>Linear
300 Quadratic
.=</p>
<p>250
.=</p>
<p>200
.=</p>
<p>150
.=</p>
<p>1
100
.=</p>
<p>50
.=</p>
<p>0
0.1 0.3 0.5 0.7 0.9 1.1 1.3 1.5 1.7 1.9 2.1 2.3 2.5 2.7
.=</p>
<p>Absolute Error
September 12, 2004 Constraint Programming 2002, Cornell 28
.=</p>
<p>Count.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>QR: RMSE vs. Subset Size
1.2
.=</p>
<p>1
.=</p>
<p>0.8
.=</p>
<p>0.6
RMSE of the linear model
.=</p>
<p>0.4
.=</p>
<p>RMSE of the complete model
0.2
.=</p>
<p>0
0 10 20 30 40 50 60
.=</p>
<p>September 12, 2004 Constraint Programming 2002, Cornell 29.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Cost of Omission (subset size 6)
.=</p>
<p>BG edge density * Integer
slack  L1 norm
.=</p>
<p>Integer slack L1 norm
.=</p>
<p>BGG min good degree * 
Clustering coefficient
.=</p>
<p>Clustering deviation *
Integer slack L1 norm
.=</p>
<p>BGG min good degree *
BGG max bid degree
.=</p>
<p>Clustering coefficient *
Average minimum path
.=</p>
<p>length
.=</p>
<p>0 10 20 30 40 50 60 70 80 90 100
.=</p>
<p>September 12, 2004 Constraint Programming 2002, Cornell 30.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>What’s Next?
.=</p>
<p>Constructing algorithm portfolios
combine several uncorrelated algorithms
good initial results for WDP
.=</p>
<p>Tuning distributions for hardness 
releasing new version of CATS
.=</p>
<p>September 12, 2004 Constraint Programming 2002, Cornell 31.=</p>
</div>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Summary
.=</p>
<p>Algorithms are predictable
Empirical hardness can be studied in a disciplined way
.=</p>
<p>Once again: Structure matters!
Uniform distributions aren’t the best testbeds
Constraint graphs are very useful
Hypothesis: good heuristics make good features (e.g. LP)
.=</p>
<p>Our methodology is general and can be 
applied to other problems!
.=</p>
<p>September 12, 2004 Constraint Programming 2002, Cornell 32.=</p>
</div>
</body>
		<back>
			<div type="references">

				<listBibl>


				</listBibl>
			</div>
		</back>
	</text>
</TEI>
