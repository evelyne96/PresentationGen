<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /mnt/sda1/Dissertation/grobid/grobid-0.5.6/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Motivation Level-0 Meta-Models Conclusions Level-0 Meta-Models for Predicting Human Behavior in Games (EC&apos;14)</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2014-06-12">June 12, 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Wright</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of British Columbia</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Leyton-Brown</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of British Columbia</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Motivation Level-0 Meta-Models Conclusions Level-0 Meta-Models for Predicting Human Behavior in Games (EC&apos;14)</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2014-06-12">June 12, 2014</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.5.6" ident="GROBID" when="2019-12-23T23:49+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Modifications to a game that don't change Nash equilibrium predictions at all can cause large changes in how human subjects play the game <ref type="bibr">[Goeree &amp; Holt 2001]</ref> In Traveler's Dilemma: When the penalty is large, people play much closer to Nash equilibrium But the size of the penalty does not affect equilibrium Clearly Nash equilibrium is not the whole story Behavioral game theory proposes a number of models to better explain human behavior</p><p>In previous work <ref type="bibr">[Wright &amp; Leyton-Brown, 2010</ref>; 2014a], we compared several behavioral models' predictive performance. Nash w/error Lk Poisson-CH QRE QLk QCH-sp-uniform  In previous work <ref type="bibr">[Wright &amp; Leyton-Brown, 2010</ref>; 2014a], we compared several behavioral models' predictive performance. Quantal cognitive hierarchy is the current state of the art model. Quantal cognitive hierarchy (QCH)</p><p>Agents' levels drawn from a distribution g</p><p>An agent of level m responds to the truncated, true distribution of levels from 0 to m − 1</p><p>Agents quantally respond to their beliefs Minimax regret is not informative: 60 for all actions e.g., Player 1 plays X; if Player 2 plays C, his regret is 60 50, 49 is the fairest outcome, so Y is minmin unfair Y and Z maximize minimum payoff (40 vs. 10 for X) Y leads to the highest sum of utilities (90 + 70 = 160) X has the highest best-case utility <ref type="formula">(100)</ref> Action X's weight: w 0 + w maxmax Action Y 's weight: w 0 + w minmin + w total + w fairness Action Z's weight: w 0 + w minmin Weighted linear meta-model for level-0 agents dramatically improved the performance of all three iterative models.</p><formula xml:id="formula_0">π i,0 (a i ) = |A i | −1 , π i,m (a i ) = QBR i (π −i,0:m−1 ; λ) π i,0:m−1 = m−1 =0 π i, g( ) m−1 =0 g( ) EC</formula><p>Almost erases the difference between the models themselves. Weighted linear meta-model for level-0 agents dramatically improved the performance of iterative models. Strong evidence for the existence of level-0 agents.</p><p>For any meta-model, including uniform! Contrary to conventional wisdom. Weighted linear meta-model for level-0 agents dramatically improved the performance of iterative models. Strong evidence for the existence of level-0 agents.</p><p>For any meta-model, including uniform! Contrary to conventional wisdom.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>is by far the highest-weighted feature All the features quite well identified linear =⇒ much lower variance estimates Predicts that about half the population is level-</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head></head><label></label><figDesc>For each action, compute a sum of weights for features that are both informative and that "fire", plus a noise weight.</figDesc><table>'14: June 12, 2014 
James Wright &amp; Kevin Leyton-Brown 

Motivation 

Level-0 Meta-Models 
Conclusions 

Level-0 

Level 0 

$??? 
$???? $???? 

0 

1 

A 
B 
C 

? ? 

$??? 
$???? $???? 

0 

1 

A 
B 
C 

Uniform randomization (the usual assumption) is implausible 

And yet best performing parameters for QCH suggest large 
numbers of level-0 agents 

Level-0 agents' actions influence every other level 

EC'14: June 12, 2014 
James Wright &amp; Kevin Leyton-Brown 

Motivation 

Level-0 Meta-Models 
Conclusions 

Level-0 

Level 0 

$??? 
$???? $???? 

0 

1 

A 
B 
C 

? ? 

$??? 
$???? $???? 

0 

1 

A 
B 
C 

Uniform randomization (the usual assumption) is implausible 

And yet best performing parameters for QCH suggest large 
numbers of level-0 agents 

Level-0 agents' actions influence every other level 

Take modeling level-0 behavior more seriously? 

EC'14: June 12, 2014 
James Wright &amp; Kevin Leyton-Brown 

Motivation 

Level-0 Meta-Models 
Conclusions 

Level-0 meta-model 

Define a level-0 meta-model: 

A mapping from an (arbitrary) game to a (potentially 
nonuniform) level-0 distribution over that game's actions 
Leverage some of what we know about how people reason 
nonstrategically about games 
The meta-model can have its own parameters 

Use an existing iterative model (quantal cognitive hierarchy) 
on top of the improved level-0 model to make predictions 
What distinguishes level-0 from level-1? 

Our line in the sand: no explicit beliefs about how other 
agents will play 
We say that a feature is informative if it can distinguish at least 
one pair of actions. 

prediction for a i ∝ w 0 + 

f ∈F 

I[f is informative] · I[f (a i ) = 1] · w f 
Example: Consider Player 1 

A 
B 
C 
X 100, 20 10, 67 
30, 40 
Y 
40, 35 
50, 49 
90, 70 
Z 41, 21 
42, 22 
40, 23 
Example: Consider Player 1 

A 
B 
C 
X 100, 20 10, 67 
30, 40 
Y 
40, 35 
50, 49 
90, 70 
Z 41, 21 
42, 22 
40, 23 

Minimax regret is not informative: 60 for all actions 

e.g., Player 1 plays X; if Player 2 plays C, his regret is 60 
A 
B 
C 
X 100, 20 10, 67 
30, 40 
Y 
40, 35 
50, 49 
90, 70 
Z 41, 21 
42, 22 
40, 23 

Minimax regret is not informative: 60 for all actions 

e.g., Player 1 plays X; if Player 2 plays C, his regret is 60 

50, 49 is the fairest outcome, so Y is minmin unfair 
A 
B 
C 
X 100, 20 10, 67 
30, 40 
Y 
40, 35 
50, 49 
90, 70 
Z 41, 21 
42, 22 
40, 23 

Minimax regret is not informative: 60 for all actions 

e.g., Player 1 plays X; if Player 2 plays C, his regret is 60 

50, 49 is the fairest outcome, so Y is minmin unfair 
Y and Z maximize minimum payoff (40 vs. 10 for X) 
A 
B 
C 
X 100, 20 10, 67 
30, 40 
Y 
40, 35 
50, 49 
90, 70 
Z 41, 21 
42, 22 
40, 23 

Minimax regret is not informative: 60 for all actions 

e.g., Player 1 plays X; if Player 2 plays C, his regret is 60 

50, 49 is the fairest outcome, so Y is minmin unfair 
Y and Z maximize minimum payoff (40 vs. 10 for X) 
Y leads to the highest sum of utilities (90 + 70 = 160) 
A 
B 
C 
X 100, 20 10, 67 
30, 40 
Y 
40, 35 
50, 49 
90, 70 
Z 41, 21 
42, 22 
40, 23 

Minimax regret is not informative: 60 for all actions 

e.g., Player 1 plays X; if Player 2 plays C, his regret is 60 

50, 49 is the fairest outcome, so Y is minmin unfair 
Y and Z maximize minimum payoff (40 vs. 10 for X) 
Y leads to the highest sum of utilities (90 + 70 = 160) 
X has the highest best-case utility (100) 
Example: Consider Player 1 

A 
B 
C 
X 100, 20 10, 67 
30, 40 
Y 
40, 35 
50, 49 
90, 70 
Z 41, 21 
42, 22 
40, 23 

</table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">EC'14: June 12, 2014 James Wright &amp; Kevin Leyton-Brown Motivation Level-0 Meta-Models Conclusions</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">EC'14: June 12, 2014James Wright &amp; Kevin Leyton-Brown</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Minmin Unfairness Does this action contribute to the least unfair outcome? 2 Maxmax payoff ("Optimistic") Does this action contribute to my own highest-payoff outcome? 3 Maxmin payoff ("Pessimistic") Is this action best in the (deterministic) worst case? 4 Minimax regret Does this action have the lowest maximum regret? 5 Efficiency (Total payoffs) Does this action contribute to the social-welfare-maximizing outcome? EC'14: June 12, 2014 James Wright &amp; Kevin Leyton-Brown</note>
		</body>
		<back>
			<div type="references">

				<listBibl/>
			</div>
		</back>
	</text>
</TEI>
