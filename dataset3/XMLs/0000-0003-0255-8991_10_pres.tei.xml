<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /mnt/sda1/Dissertation/grobid/grobid-0.5.6/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">System for NIST 2010 Speaker Recognition Evaluation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Penagarikano</surname></persName>
							<email>mikel.penagarikano@ehu.es</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Electricity and Electronics</orgName>
								<orgName type="department" key="dep2">NIST SRE10 Evaluation Workshop</orgName>
								<orgName type="institution" key="instit1">University of the Basque Country System University of the Basque Country</orgName>
								<orgName type="institution" key="instit2">University of the Basque Country</orgName>
								<address>
									<settlement>Brno</settlement>
									<country>Spain, Czech Republic</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Varona</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Electricity and Electronics</orgName>
								<orgName type="department" key="dep2">NIST SRE10 Evaluation Workshop</orgName>
								<orgName type="institution" key="instit1">University of the Basque Country System University of the Basque Country</orgName>
								<orgName type="institution" key="instit2">University of the Basque Country</orgName>
								<address>
									<settlement>Brno</settlement>
									<country>Spain, Czech Republic</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">L J</forename><surname>Diez</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Electricity and Electronics</orgName>
								<orgName type="department" key="dep2">NIST SRE10 Evaluation Workshop</orgName>
								<orgName type="institution" key="instit1">University of the Basque Country System University of the Basque Country</orgName>
								<orgName type="institution" key="instit2">University of the Basque Country</orgName>
								<address>
									<settlement>Brno</settlement>
									<country>Spain, Czech Republic</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Rodriguez-Fuentes</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Electricity and Electronics</orgName>
								<orgName type="department" key="dep2">NIST SRE10 Evaluation Workshop</orgName>
								<orgName type="institution" key="instit1">University of the Basque Country System University of the Basque Country</orgName>
								<orgName type="institution" key="instit2">University of the Basque Country</orgName>
								<address>
									<settlement>Brno</settlement>
									<country>Spain, Czech Republic</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bordel</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Electricity and Electronics</orgName>
								<orgName type="department" key="dep2">NIST SRE10 Evaluation Workshop</orgName>
								<orgName type="institution" key="instit1">University of the Basque Country System University of the Basque Country</orgName>
								<orgName type="institution" key="instit2">University of the Basque Country</orgName>
								<address>
									<settlement>Brno</settlement>
									<country>Spain, Czech Republic</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">System for NIST 2010 Speaker Recognition Evaluation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>24/06/2010 -25/06/2010 1</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.5.6" ident="GROBID" when="2019-12-24T15:33+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0" /><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>FalseFalse</head><label></label><figDesc>Alarm probability (in %) 24/06/2010 -25/06/2010 NIST SRE10 Evaluation Workshop, Brno, Czech Republic 8DET curves, core-core, conditions 07Alarm probability (in %)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head></head><label></label><figDesc>Partitioning of the previous SRE databases grep -f train.regexp *.train.$gender.vector &gt; train.$gender.vector grep -f test.regexp *.test.$gender.vector &gt; test.$gender.vector Interview In Train And Nve Phoncall Over Tel Channel In Test 90 NIST SRE10 core-core 03 -Interview In Train And Nve Phoncall Over Tel Channel In Test</figDesc><table>Universal Background Models (UBM) 
Channel Compensation (CHC) 
SVM Impostors (IMP) 
Z-Norm score normalization (SN-ZNorm) 
T-Norm score normalization (SN-TNorm) 
Development set 

spkrs SRE04 SRE05 SRE06 SRE08 FU08 

SRE04 
310 
0 
0 
0 
0 

SRE05 
0 
525 
348 
0 
0 

SRE06 
0 
348 
949 
112 
0 

SRE08 
0 
0 
112 
1336 
150 

FU08 
0 
0 
0 
150 
150 

Development set 

FU08 
0 
0 
0 
150 
150 

signals 
Female 
Male 
Total 

UBM 
2804 
2119 
4923 

CHC 
4586 
3531 
8117 

IMP 
2780 
2094 
4874 

signals FU08 

CHC 
4208 

Tnorm 
1993 

ZNorm 2087 

24/06/2010 -25/06/2010 
NIST SRE10 Evaluation Workshop, Brno, Czech Republic 
2 

IMP 
2780 
2094 
4874 

TNorm 
1479 
960 
2439 

ZNorm 
1403 
1146 
2549 

signals SRE08 SRE08* devA 
devB 

train 
3263 
3149 
1621 
1528 

test 
6377 
6211 
3306 
2905 

(*) 112 speakers from SER06 were removed 

The EHU Speaker Recognition System 

Preprocessing 
Feature Extraction 
UBM 
Preprocessing 

• Qualcomm-ICSI-OGI noise 
reduction (Wiener Filter) 
• Interviewer attenuation 

Feature Extraction 

• 13MFCC, CMS, FW, ∆+∆∆ 
• Sautrela Toolkit 

UBM 

• Gender dependent 
• 1024 components 
• Sautrela Toolkit 

GMM-SVM &amp; LE-GMM 

• SUNSDV-SRE08 recipe 

GLDS-SVM 
JFA 

• BUT Matlab JFA recipe 
• SUNSDV-SRE08 recipe 
• Eigenchannels: 20+20+40 
• Sautrela Toolkit + SVMTorch 

• Feature domain CC from Suff-Stat 
• Sautrela Toolkit + SVMTorch 

• BUT Matlab JFA recipe 
• 200 eigenvoices 
• 100 eigenchannels 

ZT normalization 

• Channel type condition: 1MIC , 0MIC , 2MIC 
• Channel &amp; gender dependent ZT 

ZT normalization 

• Channel type condition: 1MIC , 0MIC , 2MIC 
• Channel &amp; gender dependent ZT 

24/06/2010 -25/06/2010 
NIST SRE10 Evaluation Workshop, Brno, Czech Republic 
3 

Fusion &amp; Calibration 

• Side info conditional fusion &amp; calibration (channel type + gender) 
• Hard accept/reject decisions by Bayes threshold of 6,907 
• FoCal Toolkit 
grep -f train.regexp *.$gender.vector &gt; train.$gender.vector 
grep -f test.regexp *.$gender.vector &gt; test.$gender.vector 

Original 
Debugged 

Min Cost 
EER 
Min Cost 
EER 

01 
1 
49,68 
0,5439 
2,93 

02 
1 
47,82 
0,8061 
6,65 

03 
1 
28,72 
0,4683 
4,23 

04 
1 
27,94 
0,6931 
5,28 

05 
1 
37,01 
0,7270 
4,38 

24/06/2010 -25/06/2010 
NIST SRE10 Evaluation Workshop, Brno, Czech Republic 
4 

05 
1 
37,01 
0,7270 
4,38 

06 
0,7936 
6,93 
0,7936 
6,93 

07 
0,7270 
8,64 
0,7270 
8,64 

08 
0,3675 
2,01 
0,3675 
2,01 

09 
0,4251 
2,76 
0,4251 
2,76 

Results Analysis (core-core, cond-03 … our best) 

90 

NIST SRE10 core-core 
03 -</table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl/>
			</div>
		</back>
	</text>
</TEI>
