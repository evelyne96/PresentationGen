<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /mnt/sda1/Dissertation/grobid/grobid-0.5.6/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">The place of automatic evaluation metrics in external quality models for machine translation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2007-09">September 2007</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrei</forename><surname>Popescu-Belis</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">ISSCO / TIM / ETI</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">The place of automatic evaluation metrics in external quality models for machine translation</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2007-09">September 2007</date>
						</imprint>
					</monogr>
					<note>University of Geneva Workshop on Automatic Procedures in MT Evaluation MT Summit XI, Copenhagen, 11</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.5.6" ident="GROBID" when="2019-12-23T23:49+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Issues and answers</head><p>What does "better translation" mean? go and ask people (= language users) Could s be computed automatically, directly from S n and T n ? but this is also the goal of MT! so, could s be approximated? with what supplementary knowledge?</p><p>A consistently high s is not the only desirable property of an MT system Quality "the totality of features and characteristics of a product or service that bear on its ability to satisfy stated or implied needs" (ISO/IEC 9126) decomposed into quality characteristics, then into measurable attributes, each with internal/external metrics six categories of quality characteristics: functionality, reliability, usability, efficiency, maintainability, portability Metric "a measurement is the use of a metric to assign a value (i.e., a measure, be it a number or a category) from a scale to an attribute of an entity" (ISO/IEC 14598) 7 FEMTI refinement of ISO quality characteristics for MT <ref type="bibr">(Hovy, King &amp; Popescu-Belis, 2002)</ref>  Some metrics require human judges that cannot be replaced with software (#1 above) Some metrics can be applied both by human judges or software (#2), but software is more precise &amp; cheaper Some require human judges or complex software (#3) Some metrics require human users of the system (#4) 10 This workshop: "Automatic procedures in MT evaluation"</p><p>Underlying assumption: look only at automatic metrics for the quality of MT output such as BLEU, WER, etc. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>automatic task-based evaluation 5 Principled view of MT evaluation: FEMTI FEMTI: Framework for the evaluation of MT, started within the ISLE project http://www.issco.unige.ch/femti Two classifications / surveys characteristics of the context of use quality characteristics and metrics Helps to define evaluation plans support interfaces: specify context of use, then generate contextualized quality model 6 Important ISO-inspired notions ISO/IEC 9126 and 14598, SQUARE framework</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head></head><label></label><figDesc>FEMTI refinement of ISO quality characteristics for MT(Hovy, King &amp; Popescu-Belis, 2002) For &lt;2.4.1.3 Input to Output Translation Speed&gt; number of translated words per unit of time For &lt;2.1.3.2 Punctuation errors&gt; percentage of correct punctuation marks For &lt;2.5.2.3 Ease of dictionary update&gt; time OR effort necessary to update dictionary</figDesc><table>2.1 Functionality 
2.1.1 Accuracy 
2.1.1.1 Terminology 
2.1.1.2 Fidelity / precision 
2.1.1.3 Well-formedness 
2.1.1.3.1 Morphology 
2.1.1.3.2 Punctuation errors 
2.1.1.3.3 Lexis / Lexical choice 
2.1.1.3.4 Grammar / Syntax 
2.1.1.4 Consistency 
2.1.2 Suitability 
2.1.2.1 Target-language suitability 
2.1.2.1.1 Readability 
2.1.2.1.2 Comprehensibility 
2.1.2.1.3 Coherence 
2.1.2.1.4 Cohesion 
2.1.2.2 Cross-language / Contrastive 
2.1.2.2.1 Style 
2.1.2.2.2 Coverage of corpus-
specific phenomena 

2.1.2.3 Translation process models 
2.1.2.3.1 Methodology 
2.1.2.3.1.1 Rule-based models 
2.1.2.3.1.2 Statistically-based models 
2.1.2.3.1.3 Example-based models 
2.1.2.3.1.4 TM incorporated 
2.1.2.3.2 MT Models 
2.1.2.3.2.1 Direct MT 
2.1.2.3.2.2 Transfer-based MT 
2.1.2.3.2.3 Interlingua-based MT 
2.1.2.4 Linguistic resources and utilities 
2.1.2.4.1 Languages 
2.1.2.4.2 Dictionaries 
2.1.2.4.3 Word lists or glossaries 
2.1.2.4.4 Corpora 
2.1.2.4.5 Grammars 
2.1.2.5 Characteristics of process flow 
2.1.2.5.1 Translation preparation activities 
2.1.2.5.2 Post-translation activities 
2.1.2.5.3 Interactive translation activities 
2.1.2.5.4 Dictionary updating 
2.1.3 Interoperability 
2.1.4 Functionality compliance 
2.1.5 Security 

8 

2.2 Reliability 
2.2.1 Maturity 
2.2.2 Fault tolerance 
2.2.3 Crashing frequency 
2.2.4 Recoverability 
2.2.5 Reliability compliance 
2.3 Usability 
2.3.1 Understandability 
2.3.2 Learnability 
2.3.3 Operability 
2.3.3.1 Process management 
2.3.4 Documentation 
2.3.5 Attractiveness 
2.3.6 Usability compliance 
2.4 Efficiency 
2.4.1 Time behaviour 
2.4.1.1 Overall Production Time 
2.4.1.2 Pre-processing time 
2.4.1.3 Input to Output Tr. Speed 
2.4.1.4 Post-processing time 
2.4.1.4.1 Post-editing time 
2.4.1.4.2 Code set conversion 
2.4.1.4.3 Update time 

2.4.2 Resource utilisation 
2.4.2.1 Memory usage 
2.4.2.2 Lexicon size 
2.4.2.3 Intermediate file clean-up 
2.4.2.4 Program size 
2.5 Maintainability 
2.5.1 Analysability 
2.5.2 Changeability 
2.5.2.1 Ease of upgrading multilingual aspects 
2.5.2.2 Improvability 
2.5.2.3 Ease of dictionary update 
2.5.2.4 Ease of modifying grammar rules 
2.5.2.5 Ease of importing data 
2.5.3 Stability 
2.5.4 Testability 
2.5.5 Maintainability compliance 
2.6 Portability 
2.6.1 Adaptability 
2.6.2 Installability 
2.6.3 Portability compliance 
2.6.4 Replaceability 
2.6.5 Co-existence 
2.7 Cost (Introduction, Maintenance, Other) 

9 

Examples of metrics from FEMTI 

For &lt;2.1.1.2 Fidelity&gt; 

assessment of the correctness of the information transferred 
by human judges 

</table></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Place of automatic metrics in FEMTI</head><p>Two types of justifications for automatic MT evaluation metrics (2/2) Empirical (and frequent) justification = "black-box" the values of score s on a given test set are statistically correlated with a recognized metric applied by human judges assume that the two metrics measure the same quality Reverse engineering: how to construct such a score s? start with a set of MT sentences that are already scored by humans according to a metric s h , i.e. start with a large set of triples (S n , T n , s h (n)) train a statistical model to approximate s h and then estimate its error using cross-validation new automatic metric! But this is the same problem as statistical MT! (s h = 1) too difficultâ€¦ need to use supplementary information about correct translation(s) of the evaluation data set 14 Trainable distance-based metrics Distance-based NLP evaluation the evaluation data set (test set) contains desired output associated to the input data evaluation metrics are defined as distances between a system's output and the desired output, averaged over all items of input data Situation for MT no unique desired output for an input sentence frequent proposal: compute a distance between a system's output and a sample of correct outputs  Conclusions: two views of the future Utilitarian view a "better" system means only "better adapted to the users who wish to pay for it" -no absolute metrics task-based metrics do work, and could be automated but could this really be the whole story?</p><p>Cognitive view why did the quest for MT evaluation metrics become just another NLP problem?</p><p>with machine learning techniques, annotated data, etc.</p><p>the invariants of translation aren't well understood good candidates for ground truth components of meaning: logical form, inferences</p></div>			</div>
			<div type="references">

				<listBibl/>
			</div>
		</back>
	</text>
</TEI>
