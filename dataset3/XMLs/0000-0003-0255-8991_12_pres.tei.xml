<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /mnt/sda1/Dissertation/grobid/grobid-0.5.6/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Introduction Phone Log-Likelihood Ratio Features PLLR Dimensionality Reduction PLLR Projection PLLRs on Speaker Recognition Conclusions and Future Work Frame-Level Features Conveying Phonetic Information for Language and Speaker Recognition</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mireia</forename><surname>Diez</surname></persName>
							<email>mireia.diez@ehu.es</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Electricity and Electronics</orgName>
								<orgName type="institution" key="instit1">GTTS</orgName>
								<orgName type="institution" key="instit2">University of the Basque Country</orgName>
								<orgName type="institution" key="instit3">UPV/EHU</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Introduction Phone Log-Likelihood Ratio Features PLLR Dimensionality Reduction PLLR Projection PLLRs on Speaker Recognition Conclusions and Future Work Frame-Level Features Conveying Phonetic Information for Language and Speaker Recognition</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.5.6" ident="GROBID" when="2019-12-24T15:32+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Shifted Delta Cepstrum (SDC): characterize the language by the evolution of local variations of the spectrum around the analysis window, are specified by four parameters: N-d-P-k t-P t t+P t+P*k/2 t-P*k/2 t-d t+d t+P-d t+P+d t-P-d t-P+d t+P*k/2-d t+P*k/2+d t-P*k/2-d t-P*k/2+d </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>i-vector system</head><p>Under the i-vector modeling assumption, an utterance GMM supervector (stacking the means of a GMM which is estimated by MAP adaptation of the UBM to the input utterance) is defined as:</p><formula xml:id="formula_0">M = m + Tw</formula><p>(1) m is the utterance independent mean supervector T is the total variability matrix (a low-rank rectangular matrix) w is the so called i-vector, a normally distributed low-dimensional latent vector M is assumed to be normally distributed with mean m and covariance TT The latent vector w can be estimated from its posterior distribution conditioned to the Baum-Welch statistics </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Phone decoders</head><p>Phonemes usually span several frames. Phone-state posteriors represent shorter units and allow a better acoustic modeling of the speech Given an input sequence of acoustic observations X , they provide an acoustic posterior probability of each state s (1 &lt; s &lt; S) of each phone model i (1 &lt; i &lt; N) at each frame t, p(i|s; t) Phone-lattice-SVM approach Support Vector Machines, are discriminative models that try to find the boundaries between two classes</p><p>The phone lattice produced by a decoder i is stored for each target language j, then feature vectors are built from expected counts of phone n-grams </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Calibration and Fusion</head><p>Score Normalization Helps removing the environmental effects on the score space: Z-Norm, T-Norm, ZT-Norm</p><p>Backend Is a calibration stage that transforms the space of scores to get reliable estimates of the class probabilities, and can map scores to the space of target languages: Generative/Discriminative Gaussian backends, Logistic Regression, etc. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Evaluation Measures</head><p>Average Cost (C avg ): A combination of P miss and P fa pooled across target languages. For closed-set evaluation tasks:</p><formula xml:id="formula_1">C avg = 1 L L i=1 C miss P T P miss (i) + 1 L − 1 l N C fa (1 − P T )P fa (l T , l N ) (2)</formula><p>Average Cost (C 24 avg ): The primary measure for NIST 2011 LRE, averages the actual cost for the 24 pairs with the highest minimum cost C LLR : Evaluates system performance globally by means of a single numerical value. It only depends on the scores (not on application dependent parameters), on their ability to discriminate amongst target languages and on how well they are calibrated </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Phone Log-Likelihood Ratio Features</head><p>Phone decoder including: N phone units, represented by a model of S states. Given an input sequence of acoustic observations X , we assume that the acoustic posterior probability of each state s (1 ≤ s ≤ S) of each phone model i (1 ≤ i ≤ N) at each frame t, p(i|s, t), is output by the phone decoder</p><p>The acoustic posterior probability of a phone unit i at each frame t can be computed by: </p><formula xml:id="formula_2">p(i|t) = ∀s p(i|s, t)<label>(3)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Phone Log-Likelihood Ratio Features</head><p>In this way, the decoder outputs an n-dimensional vector of phone posteriors at each frame t:</p><formula xml:id="formula_3">p(t) = (p(1|t), p(2|t), . . . , p(n|t)) n i=1 p(i|t) = 1 (4) p(i) ∈ [0, 1] i = 1, 2, . . . , n.<label>(5)</label></formula><p>The vector p(t) defines a certain mixture of phones, the one that, according to the parameters of the phone decoder, best describes the spectral content of the analysis window. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Phone Log-Likelihood Ratio Features</head><p>Geometrically, the vector p(t) can be also interpreted as a point inside an (N − 1)-dimensional region known as standard</p><formula xml:id="formula_4">(N − 1)-simplex The standard (N − 1)-simplex ∆ (N−1)</formula><p>is the subset of points in R N given by:  Assuming a classification task with flat priors, the log-likelihood ratios at each frame t can be computed from posterior probabilities as follows:</p><formula xml:id="formula_5">PLLR(i|t) = log p(i|t) 1 (N−1) (1 − p(i|t)) i = 1, ..., N<label>(6)</label></formula><p>In this way, n log-likelihood ratios are computed at each frame t, carrying the same information as the n phone posteriors, but seemingly featuring Gaussian distributions </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>System Configuration</head><p>Voice activity detection performed by removing the feature vectors whose highest PLLR value corresponds to the integrated non-phonetic unit </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Contrastive Systems</head><p>Acoustic feature-based i-vector system </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Contrastive systems</head><p>Phone-lattice-SVM system Three phonotactic systems using BUT TRAPs/NN phone decoders for Czech, Hungarian and Russian Phone posteriors converted to phone lattices by HTK Expected counts of phone n-grams computed using the lattice tool of SRILM SVM LIBLINEAR classifier, vectors consisting of expected frequencies of phone n-grams (up to n=3) </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supervised Techniques</head><p>For each family, the posterior of each phonetic class was computed by adding the posteriors of the phones included in it, then the log-likelihood ratios were computed</p><p>Family-R: The reduced (R) set of phones used by Soufifar et al. 1 to limit the number of n-gram counts (33 phone classes)</p><p>Family-SL: this set is defined by merging Short and Long (SL) phones (31 phone classes) </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Unsupervised Techniques</head><p>Correlation: An iterative clustering algorithm is used. In each step, the algorithm merges the closest pair of phones according to the correlation among the phone posterior probabilities Frequency: The N phones with the highest posterior probabilities overall in the training set are selected and used as (reduced) phone set PCA was also tested. Since PCA is an orthogonal transformation that is assumed to deal with normally distributed data ranging in (−∞, ∞), it is not a suitable transformation to be applied on the phone posterior probability space. Instead, PCA is directly applied on the normally distributed PLLR space </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>PLLR Feature Space</head><p>Phone posterior vector p(t) = (p(1|t), p(2|t), . . . , p(N|t))</p><formula xml:id="formula_6">PLLR(i|t) = log p(i|t) (1 − p(i|t)) i = 1, ..., N<label>(7)</label></formula><p>As phone posteriors range in [0,1], PLLRs would seemingly range in (−∞, ∞) </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>PLLR Feature Space</head><p>From the simplex (space where the phone posteriors lay) and the PLLR definition, we derive the hyper-surface S where the PLLRs lay: </p><formula xml:id="formula_7">S (N−1) = r ∈ R N G(r) = N i=1 1 1 + e −r i − 1 = 0 (8)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>PLLR Projection</head><p>The hyper-surface S is asymptotically perpendicular to the basis of PLLRs, which explains the bounded distributions shown.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Demonstration</head><p>To avoid this bounding effect, we propose to project PLLRs into the hyper-plane tangential to the surface at the point where all the posteriors take the same value p i = 1 N , that is, the top of the convex surface, where the normal vector is: </p><formula xml:id="formula_8">n| r i =−log(N−1) = (N − 1) N √ N ·1<label>(9)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>PLLR Projection</head><p>In the general case (N dimensions), the kernel (null space) of the desired projection is1, then the projection matrix P is given by:</p><formula xml:id="formula_9">P = I −1 * 1<label>(10)</label></formula><p>Distribution of the PLLRs shown in previous figures after projecting them into the defined hyper-plane. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Evaluation Measures</head><p>Detection Cost Function (DCF)</p><formula xml:id="formula_10">DCF = C miss P T P miss(i) + C fa (1 − P T )P fa (L T , L N ) min{C miss P T , C fa (1 − P T )}<label>(11)</label></formula><p>EER This measure reports system performance at the operation point for which the false alarm error rate (P fa ) is equal to the miss error rate (P miss ) </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>PLLR feature space</head><p>Let us consider the case in which a subset of phones I ⊂ {1, 2, ..., N} accounts for most of the probability mass, that is, ∀i∈I p i = 1 − . As these phones tend to take all the probability mass, it follows that ∀i∈I p i → 1 and = ∀i / ∈I p i → 0 (therefore, r i → −∞ ∀i / ∈ I). Accordingly, for the normal vector n it holds:</p><formula xml:id="formula_11">lim →0 n i = 0 ∀i / ∈ I<label>(14)</label></formula><p>That is, the normal vector tends to lie in the subspace Q where the set of phones I are confined. Hence, the surface is asymptotically perpendicular to any basis defined on Q.</p><p>Back</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head></head><label></label><figDesc>Large amount of labeled data to train the models for each of the phones of their phonetic inventory</figDesc><table>Introduction 
Phone Log-Likelihood Ratio Features 
PLLR Dimensionality Reduction 
PLLR Projection 
PLLRs on Speaker Recognition 
Conclusions and Future Work 

The Task 
Datasets 
Structure of Recognition Systems 
Feature Extraction 
Baseline Acoustic System 
Baseline Phonotactic System 
Calibration and Fusion 
Evaluation Measures 

Generative modeling approach for i-vectors (each language 
modeled by a single Gaussian distribution) 
Introduction 
Phone Log-Likelihood Ratio Features 
PLLR Dimensionality Reduction 
PLLR Projection 
PLLRs on Speaker Recognition 
Conclusions and Future Work 

The Task 
Datasets 
Structure of Recognition Systems 
Feature Extraction 
Baseline Acoustic System 
Baseline Phonotactic System 
Calibration and Fusion 
Evaluation Measures 

High level features 

Most common representations are based on the information 
provided by phone decoders 

Introduction 
Phone Log-Likelihood Ratio Features 
PLLR Dimensionality Reduction 
PLLR Projection 
PLLRs on Speaker Recognition 
Conclusions and Future Work 

The Task 
Datasets 
Structure of Recognition Systems 
Feature Extraction 
Baseline Acoustic System 
Baseline Phonotactic System 
Calibration and Fusion 
Evaluation Measures 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10" validated="false"><head></head><label></label><figDesc>Open-software Temporal Patterns Neural Network phone decoders, developed by Brno University of Technology (BUT)</figDesc><table>Introduction 
Phone Log-Likelihood Ratio Features 
PLLR Dimensionality Reduction 
PLLR Projection 
PLLRs on Speaker Recognition 
Conclusions and Future Work 

Definition 
Computation 
System Configuration 
Backend and Fusion 
Development Results 
Contrastive Systems 
Results 

PLLR computation 

Introduction 
Phone Log-Likelihood Ratio Features 
PLLR Dimensionality Reduction 
PLLR Projection 
PLLRs on Speaker Recognition 
Conclusions and Future Work 

Definition 
Computation 
System Configuration 
Backend and Fusion 
Development Results 
Contrastive Systems 
Results 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11" validated="false"><head></head><label></label><figDesc>The backend setup was separately optimized for each datasetNIST 2007NIST  , 2009 LRE: ZT-Norm followed by a discriminative Gaussian backend NIST 2011 LRE: no normalization, generative Gaussian backend KALAKA-2: no normalization, no backend Feature level channel compensation: Feature normalization, feature warping, RASTA filtering.</figDesc><table>Introduction 
Phone Log-Likelihood Ratio Features 
PLLR Dimensionality Reduction 
PLLR Projection 
PLLRs on Speaker Recognition 
Conclusions and Future Work 

Definition 
Computation 
System Configuration 
Backend and Fusion 
Development Results 
Contrastive Systems 
Results 

Backend and Fusion 

Introduction 
Phone Log-Likelihood Ratio Features 
PLLR Dimensionality Reduction 
PLLR Projection 
PLLRs on Speaker Recognition 
Conclusions and Future Work 

Definition 
Computation 
System Configuration 
Backend and Fusion 
Development Results 
Contrastive Systems 
Results 

PLLR Extraction Configuration 

PLLR extraction configuration optimized on the NIST 2007 LRE dataset 
Dynamic coefficients 

System 

Cavg × 100 

C LLR 

PLLR 
3.45 
0.564 
PLLR+∆ 
2.66 
0.382 
PLLR+∆+∆∆ 
3.60 
0.506 

Static + first order dynamic 
coefficients: PLLR+∆ → 
118 features (HU) 

System 

Cavg × 100 

C LLR 

PLLR 
2.66 
0.382 
PLLR +FN 
2.95 
0.436 
PLLR +FW 
3.21 
0.435 
PLLR +RASTA 
8.67 
1.149 
Introduction 
Phone Log-Likelihood Ratio Features 
PLLR Dimensionality Reduction 
PLLR Projection 
PLLRs on Speaker Recognition 
Conclusions and Future Work 

Definition 
Computation 
System Configuration 
Backend and Fusion 
Development Results 
Contrastive Systems 
Results 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13" validated="false"><head></head><label></label><figDesc>Goal: To reduce the set of phone units in the PLLR representation</figDesc><table>Introduction 
Phone Log-Likelihood Ratio Features 
PLLR Dimensionality Reduction 
PLLR Projection 
PLLRs on Speaker Recognition 
Conclusions and Future Work 

Definition 
Computation 
System Configuration 
Backend and Fusion 
Development Results 
Contrastive Systems 
Results 

Overall Results on NIST 2007 LRE 

System 

Cavg × 100 

C LLR 

MFCC-SDC i-vector 
(a) 
2.85 
0.407 
Phonotactic 
(b) 
2.08 
0.310 
HU 
PLLR i-vector 
(c) 
2.66 
0.382 
(a)+(b) 
1.08 
0.152 
(a)+(c) 
1.40 
0.215 
(b)+(c) 
1.20 
0.166 
Fusion 

(a)+(b)+(c) 
0.82 
0.124 
Introduction 
Phone Log-Likelihood Ratio Features 
PLLR Dimensionality Reduction 
PLLR Projection 
PLLRs on Speaker Recognition 
Conclusions and Future Work 

Definition 
Computation 
System Configuration 
Backend and Fusion 
Development Results 
Contrastive Systems 
Results 

Overall Results on NIST 2009 LRE 

System 

Cavg × 100 

C LLR 

MFCC-SDC i-vector 
(a) 
2.70 
0.535 
Phonotactic 
(b) 
2.49 
0.502 
HU 
PLLR i-vector 
(c) 
2.42 
0.505 
(a)+(b) 
1.67 
0.346 
(a)+(c) 
1.79 
0.392 
(b)+(c) 
1.69 
0.357 
Fusion 

(a)+(b)+(c) 
1.48 
0.321 
Introduction 
Phone Log-Likelihood Ratio Features 
PLLR Dimensionality Reduction 
PLLR Projection 
PLLRs on Speaker Recognition 
Conclusions and Future Work 

Definition 
Computation 
System Configuration 
Backend and Fusion 
Development Results 
Contrastive Systems 
Results 

Overall Results on NIST 2011 LRE 

System 

Cavg × 100 

C LLR 

MFCC-SDC i-vector 
(a) 
5.96 
1.088 
Phonotactic 
(b) 
7.15 
1.280 
HU 
PLLR i-vector 
(c) 
5.18 
0.982 
(a)+(b) 
4.34 
0.823 
(a)+(c) 
4.00 
0.789 
(b)+(c) 
4.39 
0.829 
Fusion 

(a)+(b)+(c) 
3.63 
0.714 
Introduction 
Phone Log-Likelihood Ratio Features 
PLLR Dimensionality Reduction 
PLLR Projection 
PLLRs on Speaker Recognition 
Conclusions and Future Work 

Definition 
Computation 
System Configuration 
Backend and Fusion 
Development Results 
Contrastive Systems 
Results 

Results on Albayzin 2010 LRE 

Clean 
Noisy 
System 

Cavg × 100 

C LLR 

Cavg × 100 

C LLR 
MFCC-SDC i-vector 
(a) 
2.12 
0.176 
3.95 
0.325 
Phonotactic 
(b) 
2.35 
0.218 
7.28 
0.621 
HU 
PLLR i-vector 
(c) 
1.41 
0.127 
3.17 
0.308 
(a)+(b) 
1.10 
0.106 
2.43 
0.211 
(a)+(c) 
1.20 
0.109 
2.65 
0.227 
(b)+(c) 
1.09 
0.092 
2.65 
0.228 
Fusion 

(a)+(b)+(c) 
0.97 
0.086 
1.86 
0.168 
Introduction 
Phone Log-Likelihood Ratio Features 
PLLR Dimensionality Reduction 
PLLR Projection 
PLLRs on Speaker Recognition 
Conclusions and Future Work 

Techniques 
Results 
PCA Dimensionality Study 
Shifted Delta PLLRs 

1 Introduction 

2 Phone Log-Likelihood Ratio Features 

3 PLLR Dimensionality Reduction 

4 PLLR Projection 
Introduction 
Phone Log-Likelihood Ratio Features 
PLLR Dimensionality Reduction 
PLLR Projection 
PLLRs on Speaker Recognition 
Conclusions and Future Work 

Techniques 
Results 
PCA Dimensionality Study 
Shifted Delta PLLRs 

Dimensionality Reduction 

Static + first order dynamic coefficients: PLLR+∆ → 86 
features (CZ), 118 features (HU), 100 features (RU) 

Computational problem (for some approaches): PLLR 
representation larger than common acoustic representations 

Introduction 
Phone Log-Likelihood Ratio Features 
PLLR Dimensionality Reduction 
PLLR Projection 
PLLRs on Speaker Recognition 
Conclusions and Future Work 

Techniques 
Results 
PCA Dimensionality Study 
Shifted Delta PLLRs 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_20" validated="false"><head></head><label></label><figDesc>Reported results on the primary task of the NIST 2007 LRE Cavg × 100 GMM-MMI [Torres et.al. 08] -2.10 GSV-SVM [Torres et.al. Phone-SVM, lattices [Tong et.al. 10] 1.84 -HU, Phone-SVM, lattices [Richardson et.al. Reported results on the primary task of the NIST 2009 LRE MMI [DehakN et. al. 11] 2.30 -SVM-GSV [Torres et. al. 09] -2.30 JFA [Jancik et. al. 10] -2.02 i-vector (LDA+WCCN) [DehakN et. al. 11] 2.40 i-vector, generative [Martinez et. al. Phone-SVM [Torres et. al. 09] -2.34 HU, Phone-SVM [Mikolov et. al. Reported results on the primary task of the NIST 2011 LRE Cavg × 100 min actual i-vector (LDA) [Singer et. al. 12] 4.15 -8.90 i-vector (HLDA) [Brummer et. al. 12] Reported results on the primary task: Albayzin 2010 LRE JFA [Martinez et.al. 11] 1.86 Acoustic GMM-MMI [Martinez et.al. 11] 4.33 HU, Phone-ML [Martinez et.al. 11] 4.41 Phonotactic EN, Phone-ML [Rodriguez et.al. subsystems [Martinez et.al. 11] 1.84 5 subsystems [Rodriguez et.al. 12] 1.77 2 subsystems [Abad et.al. 10] 1.81 Fusions</figDesc><table>Introduction 
Phone Log-Likelihood Ratio Features 
PLLR Dimensionality Reduction 
PLLR Projection 
PLLRs on Speaker Recognition 
Conclusions and Future Work 

Contrastive Acoustic System 
Datasets 
Evaluation Measures 
Results 

Results on the NIST 2010 SRE 

Condition 
System 
EER 
MinDCF 
ActDCF 

MFCC 
1.86 
0.417 
0.439 
PLLR+∆ 
4.05 
0.653 
0.854 
(1) 

Interview 
same microphone 
in training and test 
Fusion 
1.40 
0.363 
0.367 

MFCC 
2.99 
0.562 
0.633 
PLLR+∆ 
6.39 
0.804 
0.819 
(2) 

Interview 
different microphone 
in training and test 
Fusion 
2.36 
0.492 
0.553 

MFCC 
3.63 
0.625 
0.848 
PLLR+∆ 
9.20 
0.862 
0.978 
(3) 
Interview training 
telephone test 
Fusion 
3.25 
0.522 
0.874 

MFCC 
1.71 
0.443 
0.475 
PLLR+∆ 
5.52 
0.690 
0.703 
(4) 

Interview training 
telephone test 
rec. over microphone 
Fusion 
1.69 
0.372 
0.406 

MFCC 
4.64 
0.600 
0.712 
PLLR+∆ 
8.41 
0.848 
0.869 
(5) 
Telephone 
in training and test 
Fusion 
4.29 
0.560 
0.688 
Introduction 
Phone Log-Likelihood Ratio Features 
PLLR Dimensionality Reduction 
PLLR Projection 
PLLRs on Speaker Recognition 
Conclusions and Future Work 

Contrastive Acoustic System 
Datasets 
Evaluation Measures 
Results 

Results on the NIST 2012 SRE 

Condition 
System 
EER MinDCF ActDCF 

MFCC 
1.77 
0.272 
0.290 
PLLR+∆ 3.12 
0.419 
0.440 
(2) 
Telephone with 
No Added Noise 
Fusion 
1.39 
0.215 
0.246 

MFCC 
1.93 
0.260 
0.294 
PLLR+∆ 3.72 
0.449 
0.481 
(5) 
Telephone 
Recorded in Noise 
Fusion 
1.64 Introduction 
Phone Log-Likelihood Ratio Features 
PLLR Dimensionality Reduction 
PLLR Projection 
PLLRs on Speaker Recognition 
Conclusions and Future Work 

Conclusions 
Future Work 

Approach 
Model 
EER 

08] 
-
1.92 
Acoustic 
Discriminative GMM-MAP [Brummer et.al. 09] 
-
1.74 
HU, 08] 
2.40 
-
Phonotactic 
EN, Phone-SVM, lattices [Richardson et.al. 08] 
1.80 
-
PLLR 
HU, i-vector, generative 
2.69 
2.66 
2 acoustic subsystems [Torres et.al. 08] 
-
1.55 
2 phonotactic subsystems [Torres et.al. 08] 
-
1.55 
3 phonotactic subsystems [BenZeghiba et.al. 12] 
-
0.90 
4 subsystems [Torres et.al. 08] 
0.93 
0.97 

Fusions 

acoustic+phonotactic+PLLR 
0.80 
0.82 
Introduction 
Phone Log-Likelihood Ratio Features 
PLLR Dimensionality Reduction 
PLLR Projection 
PLLRs on Speaker Recognition 
Conclusions and Future Work 

Conclusions 
Future Work 

Approach 
Model 
EER 
Cavg × 100 
GMM-12] 
-
3.09 

Acoustic 

i-vector (Logistic reg.) [Plchot et. al. 12] 
-
2.35 
EN, 10] 
-
3.85 
Phonotactic 
RU, Phone-SVM [Mikolov et. al. 10] 
-
3.03 
PLLR 
HU, i-vector, generative 
2.43 
2.42 
2 acoustic subsystems [Torres et. al. 09] 
-
2.00 
2 acoustic subsystems [Plchot et. al. 12] 
-
1.78 
3 phonotactic subsystems [Mikolov10] 
-
2.39 
3 phonotactic subsystems [BenZeghiba et. al. 12] 
-
1.99 
3 subsystems [Torres et. al. 09] 
-
1.64 
36 subsystems [Castaldo et. al. 10] 
-
1.16 

Fusions 

acoustic+phonotactic+PLLR 
1.47 
1.48 

Back 
Introduction 
Phone Log-Likelihood Ratio Features 
PLLR Dimensionality Reduction 
PLLR Projection 
PLLRs on Speaker Recognition 
Conclusions and Future Work 

Conclusions 
Future Work 

C 24 
avg × 100 

Approach 
Model 

-
-
10.35 
Acoustic 
GMM-SVM [HuaiYou et. al. 12] 
-
10.41 
-
RU, PCA [Brummer et. al. 12] 
-
-
14.32 
Phonotactic 
HU, n-gram i-vector [Brummer et. al. 12] 
-
-
15.42 
PLLR 
HU, i-vector, generative 
5.18 
9.83 
12.12 
5 subsystems [Singer et. al. 12] 
3.30 
-
7.00 
8 subsystems [Rodriguez et. al. 12] 
3.35 
5.09 
7.64 
3 subsystems [Brummer et. al. 12] 
-
-
8.47 
3 subsystems [HuaiYou et. al. 12] 
-
9.02 
-

Fusions 

acoustic+phonotactic+PLLR 
3.63 
6.68 
9.14 
Introduction 
Phone Log-Likelihood Ratio Features 
PLLR Dimensionality Reduction 
PLLR Projection 
PLLRs on Speaker Recognition 
Conclusions and Future Work 

Conclusions 
Future Work 

Condition 
Approach 
Model 

Cavg × 100 

11] 
3.26 
Clean 
PLLR 
HU, i-vector, generative 
1.41 
8 acoustic+phonotactic+PLLR 
0.97 
5 subsystems [Rodriguez et.al. 12] 
3.90 
2 subsystems [Abad et.al. 10] 
2.53 
Noisy 
Fusions 
acoustic+phonotactic+PLLR 
1.86 
Introduction 
Phone Log-Likelihood Ratio Features 
PLLR Dimensionality Reduction 
PLLR Projection 
PLLRs on Speaker Recognition 
Conclusions and Future Work 

Conclusions 
Future Work 

Results Using Multiple Decoders 

NIST 2011 LRE 

PLLR System 

%Cavg 

C LLR 

%C 24 

avg 

CZ (43+∆) 
5.31 
0.978 
12.46 
HU (59+∆) 
5.18 
0.982 
12.12 
RU (50+∆) 
4.70 
0.898 
11.27 
Baseline 

CZ+HU+RU 
3.79 
0.720 
9.10 

CZ (25+∆) 
5.53 
1.054 
13.62 
HU (23+∆) 
5.40 
1.015 
12.64 
RU (21+∆) 
5.13 
0.961 
11.57 
Family-MP 
Introduction 
Phone Log-Likelihood Ratio Features 
PLLR Dimensionality Reduction 
PLLR Projection 
PLLRs on Speaker Recognition 
Conclusions and Future Work 

Conclusions 
Future Work 

</table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="23">/ 76 Mireia Diez Frame-Level Features Conveying Phonetic Info. for SLR and SR</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="24">/ 76 Mireia Diez Frame-Level Features Conveying Phonetic Info. for SLR and SR</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="31">/ 76 Mireia Diez Frame-Level Features Conveying Phonetic Info. for SLR and SR</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="33">/ 76 Mireia Diez Frame-Level Features Conveying Phonetic Info. for SLR and SR</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="43">/ 76 Mireia Diez Frame-Level Features Conveying Phonetic Info. for SLR and SR</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="44">/ 76 Mireia Diez Frame-Level Features Conveying Phonetic Info. for SLR and SR</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="45">/ 76 Mireia Diez Frame-Level Features Conveying Phonetic Info. for SLR and SR</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="47">/ 76 Mireia Diez Frame-Level Features Conveying Phonetic Info. for SLR and SR</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="61">/ 76 Mireia Diez Frame-Level Features Conveying Phonetic Info. for SLR and SR</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>PLLRs on Speaker Recognition</head><p>Normalized average posteriorsp(i|s) of seven Hungarian phones on the same utterance of the TIMIT dataset for 7 different speakers. The subset of phones represents fricative labiodental consonants (f and v) and a subset of vowels (e:, :2, 2, O, u), as defined in the International Phonetic Alphabet.</p></div>			</div>
			<div type="references">

				<listBibl/>
			</div>
		</back>
	</text>
</TEI>
