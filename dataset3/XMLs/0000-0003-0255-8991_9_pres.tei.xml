<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /mnt/sda1/Dissertation/grobid/grobid-0.5.6/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">An Online An Online Speaker Tracking System Speaker Tracking System for Ambient Intelligence Environments for Ambient Intelligence Environments for Ambient Intelligence Environments for Ambient Intelligence Environments</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maider</forename><surname>Zamalloa</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">GTTS, Electricity and Electronics Department</orgName>
								<orgName type="institution">University of the Basque Country</orgName>
								<address>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Ikerlan -Technological Research Centre</orgName>
								<address>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mikel</forename><surname>Peñagarikano</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">GTTS, Electricity and Electronics Department</orgName>
								<orgName type="institution">University of the Basque Country</orgName>
								<address>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Javier</forename><surname>Luis</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rodriguez-Fuentes</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">GTTS, Electricity and Electronics Department</orgName>
								<orgName type="institution">University of the Basque Country</orgName>
								<address>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Germán</forename><surname>Bordel</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">GTTS, Electricity and Electronics Department</orgName>
								<orgName type="institution">University of the Basque Country</orgName>
								<address>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juan</forename><forename type="middle">Pedro</forename><surname>Uribe</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Ikerlan -Technological Research Centre</orgName>
								<address>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Grupo de Trabajo en Tecnologías de Software</orgName>
								<orgName type="institution">Euskal Herriko Unibertsitatea Universidad del País Vasco</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">An Online An Online Speaker Tracking System Speaker Tracking System for Ambient Intelligence Environments for Ambient Intelligence Environments for Ambient Intelligence Environments for Ambient Intelligence Environments</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.5.6" ident="GROBID" when="2019-12-24T15:33+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Resultsonline vs offline</head><p>The expected performance loss of the low-latency online system is low: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results -online vs offline</head><p>The expected performance loss of the low-latency online system is low: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results -online vs offline</head><p>The expected performance loss of the low-latency online system is low: Results support the use of a specific UBM for room and speaker set:</p><p>There is a high consistency between the UBM and target speakers But a different UBM model must be estimated for each set of target speakers</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results -Calibration</head><p>Calibration stage leads to a better performance in all cases: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results -Calibration</head><p>Calibration stage leads to a better performance in all cases: </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head></head><label></label><figDesc>Common approaches consists of two uncoupled steps:In an AmI Environment speaker detection must be continuous and real-timeIntroduction -Speaker TrackingSystem performance is compared to an offline reference system following a clasical two-stage approach Audio segmentation is done by a similar approach to well known BIC Speaker detection is carried out by computing speaker model likelihood ratios Precision (PRC) computes correctly detected target time from total target time Recall (RCL) estimates correctly detected target time from actual target time</figDesc><table>Outline 

Introduction 

The Ambient Intelligence vision 
Speaker Tracking 
Introduction -Speaker Tracking 

Speaker tracking and diarization primary application 
domains 

Telephone conversations 
Broadcast news 
Meeting recordings 

Audio Segmentation 
Speaker detection 

Speaker tracking and diarization primary application 
domains 

Telephone conversations 
Broadcast news 
Meeting recordings 

Audio recording is 
fully available before 
processing!! 

Common approaches consists of two uncoupled steps: 

Audio Segmentation 
Speaker detection 

In an AmI Environment speaker detection must be 
continuous and real-time 
Introduction -Speaker Tracking 

Speaker tracking and diarization primary application 
domains 

Telephone conversations 
Broadcast news 
Meeting recordings 

Audio recording is 
fully available before 
processing!! 

Common approaches consists of two uncoupled steps: 

Audio Segmentation 
Speaker detection 

In an AmI Environment speaker detection must be 
continuous and real-time 

State of the arte approaches are not suitable 
State of the arte approaches are not suitable 
for low 
for low--latency online speaker detection 
latency online speaker detection 

ICAART 2010 
23 January 2010, Valencia 
10 

processing!! 

Low-latency Online 
Speaker Tracking System 

System is designed for an intelligent home environment 

It tracks known speakers continuously 
The expected number of targets is low (i.e. the members of a 
family) 
The scenario requires almost instantaneous (low-latency) 
The scenario requires almost instantaneous (low-latency) 
speaker tracking decisions 

So, a very simple speaker tracking algorithm is 
designed 

Joint speaker segmentation and speaker detection is performed 
Fixed-length audio segments are defined and processed 

ICAART 2010 
23 January 2010, Valencia 
11 
Parameterization 
module 

X=(x 0 , ..., x N } 

Acoustic Vectors 

ICAART 2010 
23 January 2010, Valencia 
12 

Speaker detection 
module 

Calibration 
module 

{∆ S 1 (X), ..., ∆ S T (X)} 

A detection score per target speaker 

{C(∆ S 1 ), ..., C(∆ S T )} 

A likelihood ratio per target speaker 

Speaker Models 
{λ 1 , ..., λ T } 
Universal Background Model 
λ UBM 
Parameterization 
module 

X=(x 0 , ..., x N } 

Acoustic Vectors 

Decision 
Decision Decision 
Decision = 
= = 
= 

ICAART 2010 
23 January 2010, Valencia 
13 

Speaker detection 
module 

Calibration 
module 

{∆ S 1 (X), ..., ∆ S T (X)} 

A detection score per target speaker 

{C(∆ S 1 ), ..., C(∆ S T )} 

A likelihood ratio per target speaker 

Speaker Models 
{λ 1 , ..., λ T } 
Universal Background Model 
λ UBM 
Parameterization Module 

Channel Normalization: Dynamic Cepstral Mean Normalization 
Acoustic Vectors: 12 Mel Frequency Cepstral Coefficients (MFCC) and 
deltas 
Parameterization is done by Sautrela Framework (Penagarikano, www.sautrela.org) 

Speaker Detection Module 

Acoustic Speaker Models 

A Gaussian Mixture Model (GMM) adapted from an universal model 
In adaptation, non-overlapped single-speakers segments are used 

Given 
and the parameterized acoustic segment X, the speaker 
detection score 
is: 

where 
is the log-likelihood of X given 
Calibration Module 

Maps detection scores to likelihood ratios by applying a linear 
transform C: 

Scaling parameters are computed over a development corpus 
Scaling parameters are computed over a development corpus 

Optimization process is based on Maximizing Mutual Information 

Minimum expected cost based decision threshold is applied over 
calibrated scores 

Calibration is done by FoCal toolkit (Brummer, sites.google.com/site/nikobrummer/focal) 

ICAART 2010 
23 January 2010, Valencia 
15 

Experimental setup 

AMI (Augmented Multipart Interaction) Corpus 

Real-time human interaction in the context of smart meeting 
rooms 
Audio &amp; video data collected in 3 instrumented rooms (Edinburgh, 
IDIAP, TNO) 
4 english (mostly non-native) speakers per meeting; 4 meetings 

ICAART 2010 
23 January 2010, Valencia 
16 

4 english (mostly non-native) speakers per meeting; 4 meetings 
per session; 30 minutes meetings 

Experiments are based on 15 Edinburgh sessions 

3 speakers act as target, the fourth one as impostor 
Two independent subsets are defined: 

Development (Dev) : 8 sessions (32 meetings) 
Evaluation (Eval) : 7 sessions (28 meetings) 

Dev and Eval sets consist of: 

Train dataset: 2 meetings per session (random selection) 
Test dataset: 2 meetings per session 

For time references AMI corpus manual annotations are used 

Experimental setup 

Two online speaker tracking systems which differ in UBM 
estimation data: 

UBM-g uses15 gender-balanced meetings from all sites except 
Edinburgh 
UMB-t uses only speech data from target speakers 

System performance is compared to an offline reference 

ICAART 2010 
23 January 2010, Valencia 
17 

Performance measure: 

ranges from 0 to 1, where: 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head></head><label></label><figDesc>(Have a look at the paper for the results of the reference system) Calibration stage leads to a better performance in all cases:(Have a look at the paper for the results of the reference system)ConclusionsA online speaker tracking for an AmI scenario is proposed Processes continuous audio streams Outpus an identification decision for fixed-length segmentsThe system performance is compared to a referenceThe system performance is compared to a reference system based on offline segmentation Even if speaker tracking actually takes advantage from an offline segmentation, online system presents little degradation Depending on the scenario and required latency, offline segmentation may not be feasible Better results are attained when the UBM matches test conditions (same room, same speakers)</figDesc><table>Uncalibrated 
Uncalibrated Uncalibrated 
Uncalibrated 

PRC 
RCL 
F measure 

Dev 
UBM 
UBM UBM 
UBM---
-g g g 
g 
0.66 
0.66 0.66 
0.66 
0.92 
0.92 0.92 
0.92 
0.77 
0.77 0.77 
0.77 

Calibrated 
Calibrated Calibrated 
Calibrated 

PRC 
RCL 
F measure 

0.81 
0.81 0.81 
0.81 
0.8 
0.8 0.8 
0.8 
0.81 
0.81 0.81 
0.81 

ICAART 2010 
23 January 2010, Valencia 
24 

Dev 
UBM 
UBM UBM 
UBM---
-t t t 
t 
0.67 
0.67 0.67 
0.67 
0.91 
0.91 0.91 
0.91 
0.77 
0.77 0.77 
0.77 

Eval 
UBM 
UBM UBM 
UBM---
-g g g 
g 
0.69 
0.69 0.69 
0.69 
0.92 
0.92 0.92 
0.92 
0.78 
0.78 0.78 
0.78 

UBM 
UBM UBM 
UBM---
-t t t 
t 
0.71 
0.71 0.71 
0.71 
0.91 
0.91 0.91 
0.91 
0.8 
0.8 0.8 
0.8 

0.82 
0.82 0.82 
0.82 
0.83 
0.83 0.83 
0.83 
0.82 
0.82 0.82 
0.82 

0.78 
0.78 0.78 
0.78 
0.85 
0.85 0.85 
0.85 
0.8 
0.8 0.8 
0.8 

0.81 
0.81 0.81 
0.81 
0.85 
0.85 0.85 
0.85 
0.83 
0.83 0.83 
0.83 

2.56% relative 
improvement 

Results -Calibration 

Uncalibrated 
Uncalibrated Uncalibrated 
Uncalibrated 

PRC 
RCL 
F measure 

Dev 
UBM 
UBM UBM 
UBM---
-g g g 
g 
0.66 
0.66 0.66 
0.66 
0.92 
0.92 0.92 
0.92 
0.77 
0.77 0.77 
0.77 

Calibrated 
Calibrated Calibrated 
Calibrated 

PRC 
RCL 
F measure 

0.81 
0.81 0.81 
0.81 
0.8 
0.8 0.8 
0.8 
0.81 
0.81 0.81 
0.81 

ICAART 2010 
23 January 2010, Valencia 
25 

Dev 
UBM 
UBM UBM 
UBM---
-t t t 
t 
0.67 
0.67 0.67 
0.67 
0.91 
0.91 0.91 
0.91 
0.77 
0.77 0.77 
0.77 

Eval 
UBM 
UBM UBM 
UBM---
-g g g 
g 
0.69 
0.69 0.69 
0.69 
0.92 
0.92 0.92 
0.92 
0.78 
0.78 0.78 
0.78 

UBM 
UBM UBM 
UBM---
-t t t 
t 
0.71 
0.71 0.71 
0.71 
0.91 
0.91 0.91 
0.91 
0.8 
0.8 0.8 
0.8 

0.82 
0.82 0.82 
0.82 
0.83 
0.83 0.83 
0.83 
0.82 
0.82 0.82 
0.82 

0.78 
0.78 0.78 
0.78 
0.85 
0.85 0.85 
0.85 
0.8 
0.8 0.8 
0.8 

0.81 
0.81 0.81 
0.81 
0.85 
0.85 0.85 
0.85 
0.83 
0.83 0.83 
0.83 

3.75% relative 
improvement 

ICAART 2010 
23 January 2010, Valencia 
26 

Thank you! 

ICAART 2010 
23 January 2010, Valencia 
27 
</table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">{as 0 , ..., as L } Acoustic Samples (fixed-length: 1sec)</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="23">January 2010, Valencia 14 M. Penagarikano and G. Bordel, "SAUTRELA: A Highly Modular Open Source Speech Recognition Framework", In Proceedings of the IEE Automatic Speech Recognition and Understanding Workshop (ASRU), 2005.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">GTTS, Electricity and Electronics Department, University of the Basque Country, Spain 2 Ikerlan -Technological Research Centre, Spain</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl/>
			</div>
		</back>
	</text>
</TEI>
