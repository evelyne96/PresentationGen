<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /mnt/sda1/Dissertation/grobid/grobid-0.5.6/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Extensions</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<title level="a" type="main">Extensions</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.5.6" ident="GROBID" when="2019-12-23T23:48+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"> <ref type="bibr">[Horvitz et al.]</ref> <p>error measure often inappropriate class boundary effects Run n algorithms in parallel <ref type="bibr">[Gomes &amp; Selman]</ref> running time always n · min-time in our case study, we did much better (1.05 · min-time) Sequential algorithm selection using MDP formalism <ref type="bibr">[Lagoudakis &amp; Littman]</ref> algorithms must be reimplemented computing a good value function at every recursive branch can be very expensive (our value function averaged 27 secs)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Future Directions</head><p>Apply these ideas to other NP-hard problems such as SAT our preliminary SAT portfolio ("SATzilla") showed very encouraging results at the SAT-2003 competition (2 nd on random data; 3 rd on "handmade" data) Study the use of SVM regression rather than least squares regression our initial results show that SVMs outperform least-squares models, albeit by a fairly small "margin"  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>We would like to acknowledge Ryan Porter, Carla Gomes and Bart Selman for their assistance . This work was supported by DARPA grant F30602-00-2-0598 and a Stanford Graduate Fellowship.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>1 .</head><label>1</label><figDesc>Trade off time taken to compute features and time taken to run the selected algorithm</figDesc><table>2. Transform response variable to achieve 
tradeoffs between absolute and relative 
prediction error 

3. Cap runtimes to significantly reduce the 
amount of time required for collecting data 

Discussion: Other Approaches 

Algorithm selection has received some 
previous study; e.g., [Rice], [Lobjois &amp; Lemaitre] 
Classification </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Boosting 1 .</head><label>1</label><figDesc>Combine uncorrelated weak classifiers into a stronger aggregate 2. Train new classifiers on instances that are hard for the aggregate 1. Algorithm Portfolios Hardness models can be used to select an algorithm to run on a per-instance basis 2. Distribution Induction To evaluate new algorithms, use portfolio hardness model as a PDF and generate problems in proportion to the time our portfolio spends on them D: original distribution of instances; H f : model of portfolio runtime (h f normalized) Generate instances from D × h f using rejection sampling</figDesc><table>The Combinatorial Auction 
Winner Determination Problem 

Find revenue-maximizing non-conflicting 
allocation of submitted bids 

Complete heuristic search algorithms we used: 
CPLEX [ILOG Inc.] 
CASS [Leyton-Brown et.al] 
GL [Gonen and Lehman] 

Data 

We generated instances from: 
Weighted Random (L2), Uniform (L3), 
Decay (L4) [Sandholm] 
Exponential (L6), Binomial (L7) [Fujishima] 
CATS: Regions, Arbitrary, Matching, 
Scheduling [Leyton-Brown et al.] 
Randomly sampled generator's parameters for 
each instance 
Took more than 3 years of CPU time just to 
collect CPLEX runtimes 

Empirical Hardness Models 

In past work, we found that quadratic 
regression can yield very accurate models 
predicting log 10 of CPLEX runtime 
root mean squared error: 0.216 (test data) 

Boosting as a Metaphor For Algorithm Design 

Kevin Leyton-Brown Eugene Nudelman James McFadden Galen Andrew Yoav Shoham 

Department of Computer Science, Stanford University, USA 

</table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl/>
			</div>
		</back>
	</text>
</TEI>
